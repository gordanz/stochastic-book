```{r child="mydefs.Rmd"}
```


# More about Random Walks
<div style="counter-reset: thechapter 4;"> </div>

## The reflection principle


Counting trajectories in order to compute probabilities is a powerful method, 
as our next  example shows. It also reveals a potential
weakness of the combinatorial approach: it works best when all $\omega$
are equally likely (e.g., when $p=\tot$ in the case of the random walk).

We start by asking a simple question: what is the typical record value
of the random walk, i.e., how far "up" (or "right" depending on your point of view) 
does it typically get? Clearly,
the largest value it can attain is $T$. This happens only when 
all coin tosses came up $+1$, an extremely unlikely event - 
its probability is $2^{-T}$. On the other hand, this maximal value is at least $0$, since
$X_0=0$, already. A bit of thought reveals that any value between those
two extremes is possible, but it is not at all easy to compute their
probabilities.

More precisely, if $\{X_n\}$ is a simple random walk with time horizon
$T$. We define its **running-maximum process** $\seqz{M}$ by
$$M_n=\max(X_0,\dots, X_n),\ \efor 0 \leq n \leq T,$$ 
and ask what the probabilities $\PP[M_n = k]$ for $k=0,\dots, n$ are. 
An easy numerical solution to this problem can be given by simulation. We reuse the function 
`simulate_walk` defined at the beginning of the chapter, but also employ a new function, called `apply` which "applies" a function to each row (or column) of a data frame or a matrix. It seems to be tailor-made for our purpose^[The function `apply` is often used as a substitute for a `for` loop because it has  several advantages over it. First, the code is much easier to read and understand. Second, `apply` can easily be parallelized. Third, while this is not such a big issue anymore, `for` loops used to be orders of magnitude slower than the corresponding `apply` in the past. R's `for` loops got much better recently, but they still lag behind `apply` in some cases. To be fair, `apply` is known to use more *memory* than `for` in certain cases.] because we want to compute the maximum of each row of the simulation matrix (remember - the row means  keep the realization fixed, but vary the time-index $n$). The syntax of `apply` is simple - it needs the data frame, the margin (rows are coded as 1 and columns as 2; so when the margin is 1, the function is applied row-wise and when the margin is 2, the function is applied column-wise) and the function to be applied (`max` in our case). The output is a vector of size `nsim` with all row-wise maxima:

```{r echo=-(1:3)}
set.seed(1232)
single_trajectory = function(T, p=0.5) {
    delta = sample(c(-1,1), size=T, replace=TRUE, prob=c(1-p,p))
    x = cumsum(delta)
    return(x)
}
simulate_walk = function(nsim, T, p = 0.5) {
  return(
    data.frame(
      X0 = 0,
      t(replicate(nsim, single_trajectory(T, p)))
    ))
}
walk = simulate_walk(nsim=100000, T=12, p=0.5)
M = apply(walk, 1, max)
hist(M, breaks=seq(-0.5, 12.5, 1), probability = TRUE)
```

The overall shape of the distribution is as we expected; the support is $\{0,1,2,\dots, 12\}$ and the 
probabilities tend to decrease as $k$ gets larger. The unexpected feature is that $\PP[ M_{12} = 1]$ seems
to be the same as $\PP[ M_{12} = 2]$. It drops after that for $k=3$, but it looks like 
$\PP[ M_{12} = 3] = \PP[ M_{12}=4]$ again. Somehow the probability does not seem to change at 
all from $2i-1$ to $2i$. 

Fortunately, there is an explicit formula for the distribution of $M_n$ and we can derive it
by a nice counting trick known as **the reflection principle**. 



As usual, we may assume without loss of generality that $n=T$ since the
values of $\delta_{n+1}, \dots, \delta_T$ do not affect $M_n$ at all.
We start by picking a level $l\in\set{1,\dots, n}$ and first compute
the probability $\PP[M_n\geq l]$ - it will turn out to be easier than
attacking $\PP[ M_n=l]$ directly. The symmetry assumption $p=1/2$ ensures that
all trajectories are equally likely, so we can do this by counting the
number of trajectories whose maximal level reached is at least $l$, and
then multiply by $2^{-n}$.

What makes the computation of $\PP[M_n \geq l]$ a bit easier than that
of $\PP[ M_n = l]$ is the following equivalence

$$M_n\geq l \text{ if and only if } X_k=l \text{ for some } k.$$

In words, the set of trajectories whose maximum is at least $l$ is
exactly the same as the set of trajectories that hit the level $l$ at
some time. Let us denote the set of trajectories $\omega$ with this property by
$A_l$, so that $\PP[ M_n \geq l] = \PP[A_l]$. 
We can further split $A_l$ into three disjoint events $A_l^{>}$, 
$A_l^{=}$ and $A_l^{<}$, depending on whether $X_n<l$, $X_n=l$ or $X_n>l$.
In the picture below, the red trajectory is in $A_l^{>}$, the green trajectory in $A_l^=$ 
 the orange one in $A_l^{<}$, while the blue one is not in $A_l$ at all. 

<center>

```{r echo=FALSE, out.width="80%"}
library(ggplot2)

omegaequal = c(0,-1,0,1,2,3,4,5,4,5,4,3)
omegagreater = c(0,1,2,3,4,5,6,5,4,3,4,5)
omegaless = c( 0,1,0,1,0,1,2,3,2,1,0,-1)
omeganot = c(0,1,2,1,0,1,0,-1,0,1,2,1)

ggplot()+
  geom_line(aes(x=0:11,y=omegaequal), color="darkgreen", size=1, alpha=0.6) +
  geom_point(aes(x=0:11,y=omegaequal), color="black") +
  geom_line(aes(x=0:11,y=omegaless), color="orange3", size=1, alpha=0.6) +
  geom_point(aes(x=0:11,y=omegaless), color="black") +
  geom_line(aes(x=0:11,y=omegagreater), color="darkred", size=1, alpha=0.6) +
  geom_point(aes(x=0:11,y=omegagreater), color="black") +
  geom_line(aes(x=0:11,y=omeganot), color="darkblue", size=1, alpha=0.6) +
  geom_point(aes(x=0:11,y=omeganot), color="black") +
  geom_line(aes(x=c(-0, 11),y=3), color="Brown", linetype="dashed") +
  geom_text(aes(x = 11.5, y=5, label="X[n]>l"),family="serif", parse=TRUE)+
  geom_text(aes(x = 11.5, y=3, label=paste("X[n] == l")),family="serif", parse=TRUE)+
  geom_text(aes(x = 11.5, y=-1, label="X[n]<l"),family="serif", parse=TRUE)+
  xlab("time")+ylab("")+
  theme_bw()+scale_x_continuous(breaks=0:11)+scale_y_continuous(breaks=-1:6)

```

</center>

With the set of all trajectories $\Omega$ partitioned into four disjoint classes, namely $A^>_l, A^=_l, A^<_l$ and $(A_l)^c$, we are ready to reveal the main idea behind the reflection principle:

<center style="margin-bottom: 20px;">
$A_l^<$ and $A_l^>$ have exactly the same number of elements, i.e., $\# A^>_l = \# A_l^<$.
</center>


To see why that is true, start by choosing a trajectory $\omega\in A_l^{>}$ and denoting by
$\tau_l(\omega)$ the *first time* $\omega$ visits the
level $l$. Since $\omega \in A^>$ such a time clearly exists. 
Then we associate to $\omega$ another trajectory, call it $\bar{\omega}$, obtained from $\omega$
in the following way:

1. $\bar{\omega}$ and $\omega$ are the same until the time $\tau_l(\omega)$. 
2. After that, $\bar{\omega}$ is the reflection of $\omega$ around the level $l$. 

Equivalently the increments of $\omega$ and $\bar{\omega}$ are exactly the same up to time $\tau(\omega)$, and exactly the opposite afterwards. In the picture below - the orange trajectory is $\omega$ and the green trajectory is its 
"reflection" $\bar{\omega}$; note that they overlap until time $5$:

<center>

```{r echo=FALSE, out.width = "80%"}
library(ggplot2)
library(latex2exp)

omegagreen = c(0,1,2,1,2,3,4,5,4,3,2,1)
omegaorange = c(0,1,2,1,2,3,2,1,2,3,4,5)

ggplot()+
  geom_line(aes(x=0:11,y=omegagreen), color="darkgreen", size=1, alpha=0.6) +
  geom_point(aes(x=0:11,y=omegagreen), color="black") +
  geom_line(aes(x=0:11,y=omegaorange), color="orange3", size=1, alpha=0.6) +
  geom_point(aes(x=0:11,y=omegaorange), color="black") +
  geom_line(aes(x=c(-0, 11),y=3), color="Brown", linetype="dashed") +
  geom_line(aes(x=c(5, 5),y=c(0.25,3)), color="gray", linetype="dotdash") +
  geom_text( aes(x = 5, y=0, label=paste(TeX("$\\tau_l(\\omega)")) ),family="serif", parse=TRUE)+
  geom_text(aes(x = 11.5, y=5, label=paste("omega")),size = 5, family="serif", parse=TRUE)+
  geom_text(aes(x = 11.5, y=1, label=paste("bar(omega)")),size = 5, family="serif", parse=TRUE)+
  xlab("time")+ylab("")+
  theme_bw()+scale_x_continuous(breaks=0:11)+scale_y_continuous(breaks=0:6)

```

</center>

Convince yourself that this procedure establishes
a bijection between the sets $A_l^{>}$ and $A_l^{<}$, making these two
sets equal in size. 

So why is it important to know that $\# A_l^> = \# A_l^<$? Because the trajectories in 
$A_l^>$ (as well as in $A_l^=$) are easy to count. 
For them, the requirement that the level 
$l$ is hit at a certain point is redundant; if you are at or above $l$
at the very end, you must have hit $l$ at a certain point.  
Therefore, $A_l^{>}$ is simply the family of those trajectories 
$\omega$ whose final positions $X_n(\omega)$ are somewhere strictly above $l$. Hence,
\begin{align}
       \PP[A_l^{>}] &= \PP[ X_n=l+1 \text{ or } X_n = l+2 \text{ or } \dots \text{ or }
     X_n=n]\\ & = \sum_{k=l+1}^n \PP[X_n = k]
\end{align}

Similarly,      $$\begin{aligned}
     \PP[ A_l^{=}] = \PP[X_n=l].\end{aligned}$$ 
Finally, by the reflection principle, 
$$\begin{aligned}
    \PP[ A_l^{<}] = \PP[A_l^{>}] = \sum_{k=l+1}^n \PP[X_n=k].\end{aligned}$$

Putting all of this
together, we get $$\begin{aligned}
    \PP[ A_l ] = \PP[ X_n=l] + 2 \sum_{k=l+1}^n \PP[X_n=k],\end{aligned}$$
so that $$\begin{aligned}
    \PP[ M_n = l ] &= \PP[ M_n \geq l] - \PP[ M_n \geq l+1]\\ & = \PP
    [A_l] - \PP
    [A_{l+1}]\\ & =
    \PP[ X_n = l] + 2 \PP[X_n = l+1] + 2\PP[X_n = l+2]+ \dots + 2\PP[ X_n=n] -\\
    & \qquad \qquad  \quad \  -
    \PP[ X_n = l+1] - 2 \PP[X_n = l+2] - \dots - 2\PP[ X_n=n]\\
    &= \PP[ X_n=l] + \PP[X_n=l+1]
    \end{aligned}$$
    
Now that we have the explicit expression
$$ \PP[ M_n = l ] = \PP[ X_n=l] + \PP[X_n = l+1] \text{ for } l=0,1,\dots, n,$$
we can shed some light on the fact on the shape of the histogram for $M_n$ we plotted above. 
Since $\PP[X_n=l]$ is $0$ if $n$ and $l$ don't have the same parity, it is clear that only
one of the probabilities $\PP[X_n=l]$ and $\PP[X_n=l+1]$ can be positive. It follows that, for
$n$ even, we have
\begin{align}
\PP[ M_n =0] &= \PP[X_n=0] + \PP[X_n=1] = \PP[X_n=0]\\
\PP[M_n=1] &= \PP[ X_n=1] + \PP[X_n=2] = \PP[X_n=2]\\
\PP[M_n=2] &= \PP[ X_n=2] + \PP[X_n=3] = \PP[X_n=2]\\
\PP[M_n=3] &= \PP[ X_n=3] + \PP[X_n=4] = \PP[X_n=4]\\
\PP[M_n=4] &= \PP[ X_n=4] + \PP[X_n=5] = \PP[X_n=4] \text{ etc.}
\end{align}
In a similar way, for $n$ odd, we have
\begin{align}
\PP[ M_n =0] &= \PP[X_n=0] + \PP[X_n=1] = \PP[X_n=1]\\
\PP[M_n=1] &= \PP[ X_n=1] + \PP[X_n=2] = \PP[X_n=1]\\
\PP[M_n=2] &= \PP[ X_n=2] + \PP[X_n=3] = \PP[X_n=3]\\
\PP[M_n=3] &= \PP[ X_n=3] + \PP[X_n=4] = \PP[X_n=3]\\
\PP[M_n=4] &= \PP[ X_n=4] + \PP[X_n=5] = \PP[X_n=5] \text{ etc.}
\end{align}

Here is a example of a typical problem where the reflection principle (i.e., the formula for $\PP[M_n=k]$) is used:

<div class="problem">
Let $X$ be a simple symmetric random walk. 
  What is the probability that $X_n\leq 0$ for all $0\leq n \leq T$? 
</div>

<div class="solution">

  This is really a question about the maximum, but in disguise.  The walk will stay negative or $0$ if and only if its running maximum $M_T$ at time $T$ takes the value $0$. By our formula for $\PP[M_n=l]$ we have
  $$ \PP[M_T=0] = \PP[X_T=0] + \PP[X_T = 1].$$
When $T=2N$ this evaluates to $\binom{2N}{N} 2^{-2N}$, and when $T=2N-1$ to
$\binom{2N-1}{N} 2^{-(2N-1)}$. 
</div>

<div class="problem">
  What is the probability that a simple symmetric random walk will reach the level $l=1$ in $T$ steps or fewer?
  What happens when $T\to\infty$?
</div>

<div class="solution">The first question is exactly the opposite of the question in our previous example, so the answer is
  $$ 1 - \PP[M_T=0] = 1- \PP[X_T=0] - \PP[X_T=1].$$
  As above, this evaluates to $\binom{2N}{N} 2^{-2N}$ when $T=2N$ is even (we skip the case of odd $T$ because it is very similar). 
  When $N\to\infty$, we expect $\binom{2N}{N}$ to go to $+\infty$ and $2^{-2N}$ to go to 
  $0$, so it is not immediately clear which term will win. 
  One way to make a guess is to think about it probabilistically: we are looking at the 
  probability $\PP[X_{2N}=0]$ that the random walk takes the 
  value $0$ after exactly $2N$ steps. Even though no  other (single) value is more 
  likely to happen, there are so many other values $X_{2N}$ could take (anything 
  from $-2N$ to $2N$ except for $0$) that we conjecture that
  its probability converges to $0$. A  formal mathematical argument which proves that
  our conjecture is, indeed correct, involves **Stirling's formula**:
  
  $$ N! \sim \sqrt{2 \pi N} \left( \tf{N}{e} \right)^N \text{ where }
   A_N \sim B_N \text{ means that } \lim_{N\to\infty} \tf{A_N}{B_N}=1. $$
  
  We write $\binom{2N}{N} = \tfrac{(2N)!}{N! N!}$ and apply Stirling's formula to each factorial (let's skip the details)
  to conclude that 
  $$ 
  \binom{2N}{N} 2^{-2n}\sim \frac{1}{\sqrt{N \pi}} 
  \text{ so that }  \lim_{N\to\infty}
  \binom{2N}{N} 2^{-2n}
  = 0 $$
</div>

The result of the previous problem implies the following important fact:

> The simple symmetric random walk will reach the level $1$, 
> with certainty, given enough time.

Indeed, we just proved that the probability of this not happening during the first $T$ steps
shrinks down to $0$ as $T\to\infty$.

But wait, there is more! By symmetry, the level $1$ can be replaced by $-1$. Also, once we hit
$1$, the random walk "renews itself" (this property is called the Strong
Markov Property and we will talk about it later), so it will eventually
hit the level $2$, as well. Continuing the same way, we get the
following remarkable result

> **Sooner or later, the symple symmetric random walk will visit any level.** 


We close this chapter with an application of the reflection principle
to a classical problem in probability and combinatorics. Feel free to skip it
if you want to. 

<div class="problemec">
Suppose that two
candidates, Daisy and Oscar, are running for office, and $T \in\N$
voters cast their ballots. Votes are counted the old-fashioned way,
namely by the same official, one by one, until all $T$ of them have been
processed. After each ballot is opened, the official records the number
of votes each candidate has received so far. At the end, the official
announces that Daisy has won by a margin of $k>0$ votes, i.e., that
Daisy got $(T+k)/2$ votes and Oscar the remaining $(T-k)/2$ votes. What
is the probability that at no time during the counting has Oscar been in
the lead?
</div>

<div class="solution">
We assume that the order in which the official counts the votes is
completely independent of the actual votes, and that each voter chooses
Daisy with probability $p\in (0,1)$ and Oscar with probability $q=1-p$.
We don't know *a priori* what $p$ is, and, as it turns out, we don't need to!

For $0 \leq n \leq T$, let $X_n$ be the number of votes received by
Daisy *minus* the number of votes received by Oscar in the first $n$
ballots. When the $n+1$-st vote is counted, $X_n$ either increases by
$1$ (if the vote was for Daisy), or decreases by 1 otherwise. The votes
are independent of each other and $X_0=0$, so $X_n$, $0\leq n \leq T$ is
a simple random walk with the time horizon $T$. The probability of an
up-step is $p\in (0,1)$, so this random walk is not necessarily
symmetric. The ballot problem can now be restated as follows:

*For a simple random walk $\set{X_n}_{0\leq n \leq T}$, what is the
probability that $X_n\geq 0$ **for all** $n$ with $0\leq n \leq T$, given that
$X_T=k$?*

The first step towards understanding the solution is the realization
that the exact value of $p$ does not matter. Indeed, we are interested
in the conditional probability $\PP[ F|G]=\PP[F\cap G]/\PP[G]$, where
$F$ denotes the set of $\omega$ whose corresponding trajectories always
stay non-negative, while the trajectories corresponding to $\omega\in G$
reach $k$ at time $T$. Each $\omega \in G$ consists of exactly $(T+k)/2$
up-steps ($1$s) and $(T-k)/2$ down steps ($-1$s), so its probability
weight is equal to $p^{ (T+k)/2} q^{(T-k)/2}$. Therefore, with $\# A$
denoting the number of elements in the set $A$, we get $$\begin{aligned}
 \PP[ F|G]=\frac{\PP[F\cap G]}{\PP[G]}=\frac{\# (F\cap G) \ p^{
    (T+k)/2} q^{(T-k)/2}}{ \# G \ p^{ (T+k)/2}
  q^{(T-k)/2}}=\frac{\#(F\cap G)}{\# G}.\end{aligned}$$ This is quite
amazing in and of itself. This conditional probability does not depend
on $p$ at all!

\medskip
Since we already know how to count the number of elements in $G$ (there
are $\binom{T}{(T+k)/2}$), "all" that remains to be done is to count the
number of elements in $G\cap F$. The elements in $G \cap F$ form a
portion of all the elements in $G$ whose trajectories don't hit the
level $l=-1$; this way, $\#(G\cap F)=\#G-\#H$, where $H$ is the set of
all paths which finish at $k$, but cross (or, at least, touch) the level
$l=-1$ in the process. Can we use the reflection principle to find
$\# H$? Yes, we can. In fact, you can convince yourself that the
reflection of any trajectory corresponding to $\omega \in H$ around the
level $l=-1$ after its last hitting time of that level produces a
trajectory that starts at $0$ and ends at $-k-2$, and vice versa. 

```{r echo=FALSE, fig.align="center", out.width="80%", message = FALSE, warning = FALSE}
library(ggplot2)
library(dplyr)
set.seed(1031)
bridge = function(T, k) {
  deltas = rep(-1,T)
  flip = sample(1:T, size=(T+k)/2, replace=FALSE)
  deltas[flip]= 1
  return(c(0,cumsum(deltas)))
}

reflect_after_hitting = function(x, level) {
  T = length(x)-1
  if (T<1) return(x)
  
  c = ifelse(level >= x[1], 1, -1)
  y = numeric(T+1)
  y[1]=x[1]
  H=1
  for (i in 1:T) {
    if (c*x[i] >= c*level)
      H = -1
    y[i+1] = y[i] + H*(x[i+1] - x[i])
  }
  return(y)
}

T=21
k=3

omega1 = bridge(T,k)
omega2 = reflect_after_hitting(omega1,-1)
time = 0:T
df = data.frame( time, omega1, omega2)
m = min(c(omega1,omega2))
M = max(c(omega1,omega2))

ggplot(data = df, aes(x=time))+
   geom_line(aes(y=-1), color="Orange", linetype="dashed") +
   geom_line(aes(y=0), color="Gray") +
   geom_line(aes(y=omega1), color="darkblue", size=1, alpha=0.6) +
   geom_line(aes(y=omega2), color="darkred", size=1, alpha=0.6) +
   geom_point(aes(y=omega1)) +
   geom_point(aes(y=omega2)) +
   annotate("text",x=T+0.6, y=-1, label="l=-1", family="serif")+
   annotate("text",x=T+0.6, y=k, label="k", family="serif")+
   annotate("text",x=T+0.6, y=-2-k, label="-2-k", family="serif")+
   xlab("time")+ylab("")+
   theme_bw()+scale_x_continuous(breaks=0:T)+scale_y_continuous(breaks = m:M)
```


The
number of paths from $0$ to $-k-2$ is easy to count - it is equal to
$\binom{T}{(T+k)/2+1}$. Putting everything together, we get
$$\PP[ F|G]=\frac{\binom{T}{n_1}-\binom{T}{n_1+1}}
{\binom{T}{n_1}}=\frac{k+1}{n_1+1},\text{ where }n_1=\frac{T+k}{2}.$$
The last equality follows from the definition of binomial coefficients
$\binom{T}{i}=\frac{T!}{i!(T-i)!}$.

The Ballot problem has a long history (going back to at least 1887) and
has spurred a lot of research in combinatorics and probability. In fact,
people still write research papers on some of its generalizations. When
posed outside the context of probability, it is often phrased as "*in
how many ways can the counting be performed ...*" (the difference being
only in the normalizing factor $\binom{T}{n_1}$ appearing in Example
above). A special case $k=0$ seems to be even
more popular - the number of $2n$-step paths from $0$ to $0$ never going
below zero is called the **$n$-th Catalan number** and equals 
 \begin{align}
   C_n=\frac{1}{n+1} \binom{2n}{n}.
 \end{align}
</div>

<div class="problemec">
Given $n\in\N$, compute $\PP[ \tau_1 = 2n+1 ]$ for a simple, but possibly biased, random walk. (Note: Clearly, $\PP[ \tau_1=2n]=0$.)
</div>
<div class="solution">
Let $A$ denote the set of all trajectories of length $2n+1$ that hit $1$ for the first time at time $2n+1$, and let $A'$ be the set of all trajectories of length $2n$ which stay at or below $0$ at all times and take the value $0$ at time $2n$. 
Clearly, each trajectory in $A$ is a trajectory in $A'$ with $1$ attached at the very end, so that $\# A = \# A'$. 

By the (last part) of the previous problem, $\# A' = \oo{n+1} \binom{2n}{n}$ (the $n^{\text{th}}$ Catalan number).
As above, all paths in $A$ have the same probability weight, namely $p^{n+1} q^n$, so 
$$ \PP[ \tau_1 = 2n+1]= p^{n+1} q^n \frac{1}{n+1} \binom{2n}{n}.$$

</div>

<div class="problemec">
Given  $p\in (0,1)$, 

1. compute $\PP[\tau_1<\infty]$;
2. decide whether or not $\EE[\tau_1]<\infty$;
3. compute, heuristically, the value of $\EE[\tau_1]$ for those $p$ for which it is finite.
</div>
<div class="solution">
<part> 1. </part>
  Using the previous problem, we need to sum the following series
  $$\sum_{k=0}^{\infty}  \PP[\tau_1=k] = \sum_{n=0}^{\infty} \PP[ \tau_1 = 2n+1] = 
  \sum_{n=0}^{\infty} p^{n+1} q^{n} \frac{1}{n+1} \binom{2n}{n} = p \sum_{n=0}^{\infty} (pq)^n \frac{1}{n+1} \binom{2n}{n}.$$
  The sum looks difficult, so let us plot a numerical approximation of its value for  different values of the parameter $p$ (the true value is plotted in orange):
  
```{r fig.align="center", fig.width = 6, fig.height = 3.5, out.width = "50%", echo=FALSE}
tol = 0.0005
P = function(p) { 
  if (p == 0.5) {
    return(1)
  } else {
    r = 2 * p * (1 - p)
    S = 0
    n = 0
    a = p
    while (a > tol) {
      S = S + a
      a = a * r * (2 * n + 1) / (n + 2)
      n = n + 1
    }
    return(S)
  }
}
x_approx = seq(0,1,length.out=22)
y_approx = sapply(x_approx,P)
x_true = seq(0,1,by=0.01)
y_true = pmin(1, x_true/(1-x_true))
df_approx = data.frame(x = x_approx, y = y_approx)
df_true = data.frame(x = x_true, y = y_true)
ggplot()+
  geom_point(data=df_approx, aes(x=x, y=y))+
  geom_line(data=df_true,aes(x=x, y=y), color="orange")+
  ylab(TeX("Approximate and true values of $\\mathbf{P} \\[ \\tau_1<\\infty\\]$"))+xlab("p")+theme_bw()
```
  
We conjecture that $\PP[ \tau_1 <\infty ] = 1$ for $p\geq \tot$, but $\PP[ \tau_1<\infty]<1$ for $p<\tot$. 
Indeed, using methods beyond the scope of these notes, it can be shown that our conjecture is true and that
$$ \PP[ \tau_1<\infty ] =\begin{cases} 1, & p \geq \tot \\ \frac{p}{q}, & p<\tot. \end{cases} $$
  
<part> 2. </part>

Since $\PP[ \tau_1= \infty]>0$ for $p<\tot$, we can immediately conclude that $\EE[\tau_1]=\infty$ in that 
case. Therefore, we assume that $p\geq \tot$, and consider the sum
$$ \EE[\tau_1] = \sum_{k=0}^{\infty} k \PP[\tau_1 = k] = \sum_{n=0}^{\infty} (2n+1) \PP[ \tau_1 = 2n+1] = \sum_{n=0}^{\infty} p^{n+1} q^{n} \frac{2n+1}{n+1} \binom{2n}{n}.$$
  We have already seen that (by Stirling's formula) we have $\binom{2n}{n} \sim \frac{2^{2n}}{\sqrt{\pi n}}$, so the question reduces to the one about convergence of the following, simpler,  series:
  $$ \sum_{n=1}^{\infty} \oo{\sqrt{n}} p^n q^{n} 2^{2n} = \sum_{n=1}^{\infty} \oo{\sqrt{n}} (4pq)^n.$$
  When $p=\tot$, we have $4pq=1$, and the series above becomes a $p$-series with $p=\tot$. Hence, it diverges. On the other hand, when $p>\tot$, $4pq<1$, the terms of the series are dominated by the terms of the convergent geometric series $\sum_{n=1}^{\infty} (4pq)^n$. Therefore, it, itself, must converge. All in all:
  $$ \EE[\tau_1] = \begin{cases} \infty, & p\leq \tot, \\ <\infty, & p > \tot. \end{cases}. $$
<part> 3. </part>

Let $a_j = \EE^{j}[\tau_1]$, where $\EE^{j}$ means that 
the random walk starts from the level $j$, i.e., $X_0=j$, instead of the usual $X_0=0$. Think about why it is plausible that the 
following relations hold for the sequence $a_n$:
$$a_1 = 0,\text{ and } a_j = 1 + p a_{j+1} + q a_{j-1}.$$ 
We guess that $a_j$ has the form $a_j = c(1-j)$, for $j<1$ (why?) and plug that guess into the above equation to get:
$$ c(1-j) = 1 + p c (-j) + q c (2-j) = 1 - c - 2 c q + c(1-j).$$
It follows that $c = \tfrac{1}{1-2q} = \tfrac{1}{p-q}$. Thus, if you believe the heuristic, we have
$$ \EE[ \tau_1 ] = \begin{cases} \frac{1}{p-q}, & p>\tot, \\ + \infty, & p\leq \tot. \end{cases}$$
(Note: If you have never seen it before, the approach we took here seems very unusual. Indeed, in order to find the value of $a_0$ we decided to compute values for the elements *of the whole sequence* $a_n$. This kind of 
thinking will appear many times later in the chapters on Markov Chains.)

</div>

## Stopping times

A **random time** is simply a random variable which takes values in the set $\N_0$ - it is random, and 
it can be interpreted as a point in time. Not all random times are created equal, though: here are three
examples based on a simple symmetric random walk $X$:

1. $\tau = 3$. This is the simplest random time - it always takes the value $3$, no matter what. It is random 
only in the formal sense of the word (just as the constant random vairbale $X=3$ *is* a random variable, but not a very interesting one). Constant random times, like $\tau=3$, are called **deterministic times**.

2. $\tau=\tau_1$ where $\tau_1$ is the first time $X$ hits the level $1$. It is no longer constant - it clearly depends on the underlying trajectory of the random walk: sometimes $\tau_1=1$; other times it can be very large. 

3. $\tau=\tau_{\max}$ where $\tau_{\max}$ is the first time $X$ takes its maximal value in the interval $\set{0,1,\dots, 100}$. The random time $\tau_{\max}$ is clearly non-constant, but it differs from $\tau=3$ or $\tau=\tau_1$ in a significant way.

Indeed, the first two examples have the following property:

> Given a time $n$, you can tell whether $\tau=n$ or not using only the information you have gathered by  time $n$.

The third one does *not*. Random times with this property are called **stopping times**. Here is a more precise, mathematical, definition. You should note that we allow our stopping times to take the value $+\infty$. The usual interpretation is that whatever the stopping time is modeling never happens. 


**Definition.** A random variable $\tau$ taking
values in $\N_0\cup\set{+\infty} = \{0,1,2,\dots, +\infty\}$ is said to be a **stopping time** with respect to the process
$\seqz{X}$ if for each $n\in\N_0$ there exists a function
$G^n:\R^{n+1}\to \set{0,1}$ such that
$$\inds{\tau=n}=G^n(X_0,X_1,\dots, X_n), \text{ for all } n\in\N_0.$$


The functions $G^n$ are called the **decision functions**, and should be thought of as a black
box which takes the values of the process $\seqz{X}$ observed up to the
present point and outputs either $0$ or $1$. The value $0$ means *keep
going* and $1$ means *stop*. The whole point is that the decision has to be
based only on the available observations and not on the future ones.

Alternatively, you can think of a stopping time as an R function whose input is
a vector which represents a trajectory $\omega$ of a random walk (or any other
process) and the output is a nonnegative integer. This function needs to be such
that if it "decides" to output the value $k$, it had to have based its decision
only on the first $k$ components of $\omega$. This means that if the output
corresponding to the input trajectory $\omega$ is $k$, and $\omega'$ is
another trajectory whose first components match those of $\omega$, then the
output corresponding to $\omega$' must also be $k$.

Now that we know how to spot stopping times, let's list some examples:

1.  The simplest examples of stopping times are (non-random)
    **deterministic times**. Just set $\tau=5$ (or $\tau=723$ or $\tau=n_0$ for any
    $n_0\in\N_0\cup\set{+\infty}$), no matter what the state of the
    world $\omega\in\Omega$ is. The family of decision rules is easy to
    construct:
    $$G^n(x_0,x_1,\dots, x_n)=\begin{cases} 1,& n=n_0, \\ 0, & n\not=
      n_0.\end{cases}.$$ Decision functions $G^n$ do not depend on the
    values of $X_0,X_1,\dots, X_n$ *at all*. A gambler who stops gambling 
    after 20 games, no
    matter what the winnings or losses are uses such a rule.

2.  Probably the most well-known examples of stopping times are **(first)
    hitting times**. They can be defined for general stochastic
    processes, but we will stick to simple random walks for the purposes
    of this example. So, let $X_n=\sum_{k=0}^n \delta_k$ be a simple random
    walk, and let $\tau_l$ be the first time $X$ hits the level $l\in\N$.
    More precisely, we use the following slightly non-intuitive but
    mathematically correct definition
    $$\tau_l=\min\sets{n\in\N_0}{X_n=l}.$$ The set $\sets{n\in\N_0}{X_n=l}$
    is the collection of all time-points at which $X$ visits the level
    $l$. The earliest one - the minimum of that set - is the first
    hitting time of $l$. In states of the world $\omega\in\Omega$ in
    which the level $l$ just never gets reached, i.e., when
    $\sets{n\in\N_0}{X_n=l}$ is an empty set, we set
    $\tau_l(\omega)=+\infty$. 
    
    In order to show that $\tau_l$ is indeed a
    stopping time, we need to construct the decision functions $G^n$,
    $n\in\N_0$. Let us start with $n=0$. We would have $\tau_l=0$ only in the
    (impossible) case $X_0=l$, so we always have $G^0(X_0)=0$. How about
    $n\in\N$. For the value of $\tau_l$ to be equal to exactly $n$, two
    things must happen:

    1.  $X_n=l$ (the level $l$ must actually be hit at time $n$), and

    2.  $X_{n-1}\not = l$, $X_{n-2}\not= l$, ..., $X_{1}\not=l$,
        $X_0\not=l$ (the level $l$ has not been hit before).

    Therefore, $$G^n(x_0,x_1,\dots, x_n)=\begin{cases}
    1,& x_0\not=l, x_1\not= l, \dots, x_{n-1}\not=l, x_n=l\\
    0,&\text{otherwise}.
    \end{cases}$$ The hitting time $\tau_2$ of the level $l=2$ for a
    particular trajectory of a symmetric simple random walk is depicted
    below: 
    
```{r echo=F, fig.align = "center", message=F, warning=F, out.width="80%"}
library(ggplot2)
library(latex2exp)

first_hitting_time = function(x,level,T=0) {
  pos = 0
  T = ifelse( T==0, length(x), min(T,length(x)))
  while (pos < T) {
    pos = pos+1
    if (x[pos] >= level)
      return(pos)
  }
  return(NaN)
}
single_trajectory = function(T, p=0.5) {
  delta = sample(c(-1,1), size=T, replace=TRUE, prob=c(1-p,p))
  x = cumsum(delta)
  return(x)
}

T=15
l=2
lbl = TeX("$\\tau_2$", output = "expression")
set.seed(10010)
omega = c(0,single_trajectory(T))
tau = first_hitting_time(omega, level=l)-1
df = data.frame(x=0:T, omega)
ggplot(data=df, aes(x=x, y=omega))+
  geom_line(color="darkblue", size=1, alpha=0.6)+ geom_point()+
  annotate("segment", x=0, xend=T, y=l, yend=l, color="orange") +
  annotate("segment", x=tau, xend=tau, y=0, yend=l, linetype="dashed", color="grey70")+
  annotate("text", x=tau+0.3, y=0.15, label=lbl, parse=T)+
  annotate("segment", x=0,xend=T, y=0, yend=0, color="grey")+
  xlab("time")+ylab("")+
  theme_bw()

```
    
3.  How about something that is *not* a stopping time? Let $T\in\N$ be
    an arbitrary time-horizon and let $\tau_{\max}$ be the last time during
    $\ft{0}{T}$ that the random walk visits its maximum during
    $\ft{0}{T}$:
    
    ```{r echo=F, message=F, warning=F, out.width="80%", fig.align="center"}
library(ggplot2)
library(latex2exp)
    
first_maximum_time = function(x,T=0) {
  if (length(x) == 0) stop("x needs to be nonempty.")
  if (T<=0 || T>length(x)) T=length(x)
  max_value = x[1]
  max_position = 1
  pos = 1
  while (pos < T) {
    pos = pos+1
    if (x[pos] > max_value) {
      max_value = x[pos]
      max_position = pos
    }
  }
  return(max_position)
}

single_trajectory = function(T, p=0.5) {
  delta = sample(c(-1,1), size=T, replace=TRUE, prob=c(1-p,p))
  x = cumsum(delta)
  return(x)
}

T=15

lbl = TeX("$\\tau_{\\max}$", output = "expression")
set.seed(100)
omega = c(0,single_trajectory(T))
tau = first_maximum_time(omega)-1
df = data.frame(x=0:T, omega)
ggplot(data=df, aes(x=x, y=omega))+
  geom_line(color="darkred", size=1, alpha=0.6)+ geom_point()+
  annotate("segment", x=tau, y=0, xend=tau, yend=omega[tau+1], linetype="dashed", color="grey70")+
  annotate("text", x=tau+0.5, y=0.15, label=lbl, parse=T)+
  annotate("segment", x=0,xend=T, y=0, yend=0, color="grey")+
  xlab("time")+ylab("")+
  theme_bw()

```
    
    If you bought a share of a stock
    at time $n=0$, had to sell it some time before or at $T$ and had the
    ability to predict the future, this is one of the points you would
    choose to sell it at. Of course, it is impossible in general to
    decide whether $\tau_{\max}=n$, for some $n\in\ft{0}{T-1}$ without the
    knowledge of the values of the random walk after $n$. 

    More
    precisely, let us sketch the proof of the fact that $\tau_{\max}$ is not a
    stopping time. Suppose, to the contrary, that it is, and let $G^n$
    be the associated family of decision functions. Consider the following two
    trajectories: $(0,1,2,3,\dots,
      T-1,T)$ and $(0,1,2,3,\dots, T-1,T-2)$. They differ only in the
    direction of the last step. They also differ in the fact that
    $\tau_{\max}=T$ for the first one and $\tau_{\max}=T-1$ for the second one. On the
    other hand, by the definition of the decision functions, we have
    $$\inds{\tau_{\max}=T-1}=G^{T-1}(X_0,\dots, X_{T-1}).$$ The right-hand side
    is equal for both trajectories, while the left-hand side equals to
    $0$ for the first one and $1$ for the second one. A contradiction.

## Wald's identity and Gambler's ruin


One of the superpowers of stopping times is that they often behave just like deterministic times. The best way to understand this statement is in the context of the beautiful *martingale theory*. Unfortunately, learning about martingales would take an entire semester, so we have to settle for an illustrative example, namely, Wald's identity.  

Let $\seq{\xi}$ be a sequence of independent and identically distributed random variables. The example you 
should keep in mind is $\xi_n = \delta_n$, where $\delta_n$ are coin tosses in the definition of a random walk. We set $X_n = \sum_{k=1}^n \xi_k$ and note that it is easy to compute $\EE[X_n]$:
$$ \EE[ X_n ] = \EE[ \xi_1+\dots + \xi_n] = \EE[\xi_1] + \dots + \EE[\xi_n] = n \mu, \text{ where } \mu = \EE[\xi_1]=\EE[\xi_2]=\dots$$
provided $\EE[\xi_1]$ exists. The expected value $\mu$ is the same for all $\xi_1,\xi_2,\dots$ because they all have the same distribution.  In words, the equality above tells us that the expected value of $X$ moves with *speed* $\mu$. Wald's identity tells us that the same thing is true when the deterministic time $n$ is replaced by a stopping time. To understand its statement below, we must first introduce a bit more notation. Let $\seqz{X}$ be a 
stochastic process, and let $\tau$ be a random time which never takes the value $+\infty$. Remember that $X_0, X_1, \dots$ are random variables, i.e., functions of the elementary outcome $\omega\in\Omega$. The same is true for $\tau$. Therefore, in order to define the *random variable* $X_{\tau}$ we need to specify what its value is for any given $\omega$:
$$ X_{\tau} (\omega) = X_{n}(\omega) \text{ where } n=\tau(\omega).$$
This is exactly what you would expect; the elementary outcome $\omega$ not only tells us which trajectory of the process to consider, but also the time at which to do it. Note that when $\tau=n$ is a deterministic time, $X_{\tau}$ is exactly $X_n$. 

**Theorem.** (Wald's identity) Let $\seq{\xi}$ be a sequence of independent and identically distributed random variables, and let $X_n = \sum_{k=1}^n \xi_k$ be the associated random walk. If $\EE[ \abs{\xi_n}]<\infty$ and $\tau$ is a stopping time for $\seqz{X}$ such that $\EE[\tau]<\infty$, then 
$$ \EE[X_{\tau}] = \EE[\tau] \mu \text{ where } \mu = \EE[\xi_1] = \EE[\xi_2] = \dots $$

 
Before we prove this theorem, here is a handy identity:

<div class="problem">
(The "tail formula" for the expectation) Let $\tau$ be an
$\N_0$-valued random variable. Show that 
$$\EE[\tau]=\sum_{k=1}^{\infty} \PP[\tau \geq k].$$
</div>
<div class="solution">
Clearly, $\PP[\tau\geq k] = \PP[ \tau=k] + \PP[\tau=k+1]+\dots$. 
Therefore, 

$$ 
\begin{array}{cccccccc}
\sum_{k=1}^{\infty} \PP[\tau \geq k] &=& \PP[ \tau=1]   &+& \PP[\tau=2] &+& \PP[\tau=3] &+& \dots  \\
&& &+& \PP[\tau=2] &+& \PP[\tau=3] &+& \dots \\
&& &&  &+& \PP[\tau=3] &+& \dots \\
&& && && &+& \dots
\end{array}
$$
If you look at the "columns", you will realize that the expression $\PP[\tau=1]$ appears in this sum once, $\PP[\tau=2]$ twice, $\PP[\tau=3]$ three times, etc.
Hence
$$\sum_{k=1}^{\infty} \PP[ \tau\geq k] = \sum_{n=1}^{\infty} n \PP[\tau=n] = \EE[\tau].$$
</div>
<div class="problemec">
  Prove Wald's identity.
</div>
<div class="solution">
Here is another representation of the random variable $X_{\tau}$:
$$X_{\tau} = \sum_{k=1}^{\tau} \xi_k=\sum_{k=1}^{\infty} \xi_k \inds{k\leq \tau}.$$ The idea
behind it is simple: add all the values of $\xi_k$ for $k\leq
\tau$ and keep adding zeros (since $\xi_k \inds{k\leq \tau}=0$ for $k>\tau$)
after that. Taking expectation of both sides and switching $\EE$ and
$\sum$ (this can be justified, but the argument is technical and we omit
it here) yields: $$
 \EE[\sum_{k=1}^{\tau} \xi_k]=\sum_{k=1}^{\infty} \EE[ \inds{k\leq \tau}\xi_k].
$$ Let us examine the term $\EE[\xi_k\inds{k\leq \tau}]$ in
some detail. We first note that
$$\inds{k\leq \tau}=1-\inds{k>\tau}=1-\inds{k-1\geq
  \tau}=1-\sum_{j=0}^{k-1}\inds{\tau=j},$$
  so that
  $$
  \EE[\xi_k \inds{k\leq \tau}]=\EE[\xi_k]-\sum_{j=0}^{k-1}\EE[ \xi_k
\inds{\tau=j} ].$$ By the assumption that $\tau$ is a stopping time, the
indicator $\inds{\tau=j}$ can be represented as
$\inds{\tau=j}=G^j(X_0,\dots, X_j)$, and, because each $X_i$ is just a sum
of the increments $\xi_1, \dots, \xi_i$, we can actually write $\inds{\tau=j}$ as a function of
$\xi_1,\dots, \xi_j$ only: $\inds{\tau=j}=H^j(\xi_1,\dots, \xi_j).$ By
the independence of $(\xi_1,\dots, \xi_j)$ from $\xi_k$ (because $j<k$)
we have 
\begin{align}
    \EE[\xi_k \inds{\tau=j}]&=\EE[ \xi_k H^j(\xi_1,\dots, \xi_j)]=
   \EE[\xi_k] \EE[ H^j(\xi_1,\dots, \xi_j)]=\EE[\xi_k] \EE[\inds{\tau=j}]=
   \EE[\xi_k]\PP[T=j].
\end{align}
 Therefore, 
 \begin{align}
    \EE[\xi_k \inds{k\leq \tau}]&=\EE[\xi_k]-\sum_{j=0}^{k-1} \EE[\xi_k]
   \PP[\tau=j]=\EE[\xi_k] \PP[\tau\geq k] =\mu \PP[\tau\geq k],
\end{align}
 where the last equality follows from the fact that all $\xi_k$ have the same expectation, namely $\mu$.


 
Putting it all together, we get
\begin{align}
    \EE[X_{\tau}]&=\EE[\sum_{k=1}^{\tau} \xi_k]=\sum_{k=1}^{\infty}
   \mu \PP[\tau\geq k]=\mu \sum_{k=1}^{\infty} \PP[\tau\geq
   k]= \EE[\tau] \mu,
\end{align}
where we use the  "tail formula" to get  the last equality.
</div>
<div class="problem">
  Show, by giving an example, that Wald's identity does not necessarily hold if $\tau$ is not a stopping time.
</div>
<div class="solution">
  Let $X$ be a simple symmetric random walk, and let $\tau$ be a random time constructed like this:
  \begin{align}
    \tau = \begin{cases} 1, & X_1=1 \\ 0,& X_1=-1. \end{cases}
  \end{align}
  Then, 
  \begin{align}
    X_{\tau} = \begin{cases} X_1, & X_1=1 \\ X_0, & X_1=-1, \end{cases} = 
    \begin{cases} 1, & X_1=1 \\ 0,& X_1=-1. \end{cases}
  \end{align}
  and, therefore, $\EE[ X_{\tau}] = 1 \cdot 1/2 + 0 \cdot 1/2 = 1/2$. On the other hand $\mu=\EE[\xi_1]=0$ and $\EE[\tau] = 1/2$, so $1/2 = \EE[X_{\tau}] \ne \EE[\tau] \mu = 0$. 
  
  It is clear that $\tau$ cannot be a stopping time, since Wald's identity would hold for it if it were.
  To see that it is not more directly, consider the event when $\tau=0$. 
  Its occurrence depends on whether $X_1=1$ or not, which is not known at time $0$.
</div>

A famous use of Wald's identity is in the solution of the following classical problem:

<div class="problem">
A gambler starts with $\$x$ dollars and repeatedly plays a game in
which she wins a dollar with probability $\tot$ and loses a dollar with
probability $\tot$. She decides to stop when one of the following two
things happens:

1.  she goes bankrupt, i.e., her wealth hits $0$, or

2.  she makes enough money, i.e., her wealth reaches some predetermined level $a>x$.

The "Gambler's ruin"  problem (dating at least to 1600s)  asks
the following question: what is the probability that the gambler will
make $a$ dollars before she goes bankrupt?
</div>

<div class="solution">
Let the gambler's "wealth" $\seqz{W}$ be 
  modeled by a simple random walk starting
from $x$, whose increments $\xi_k=\delta_k$ are coin-tosses. Then
$W_n=x+X_n$, where $X_n = \sum_{k=1}^n \xi_k$ is a SSRW. Let $\tau$ be the
time the gambler stops. We can represent $\tau$ in two different (but
equivalent) ways. On the one hand, we can think of $T$ as the smaller of
the two hitting times $\tau_{-x}$ and $\tau_{a-x}$ of the levels $-x$ and
$a-x$ for the random walk $\seqz{X}$ (remember that $W_n=x+X_n$, so
these two correspond to the hitting times for the process $\seqz{W}$ of
the levels $0$ and $a$). On the other hand, we can think of $\tau$ as the
first hitting time of the two-element *set* $\set{-x,a-x}$ for the
process $\seqz{X}$. In either case, it is quite clear that $\tau$ is a
stopping time (can you write down the decision functions?). 

When we
talked about the maximum of the simple symmetric random walk, we proved
that it hits any value if given enough time. Therefore, the probability
that the gambler's wealth will remain strictly between $0$ and $a$
forever is zero. So, $\PP[T<\infty]=1$.

\medskip

What can we say about the random variable $X_{\tau}$ - the gambler's wealth
(minus $x$) at the *random* time $\tau$? Clearly, it is either equal to
$-x$ or to $a-x$, and the probabilities $p_0$ and $p_a$ with which it
takes these values are exactly what we are after in this problem. We
know that, since there are no other values $X_{\tau}$ can take, we must have
$p_0+p_a=1$. Wald's identity gives us another equation for
$p_0$ and $p_a$: 
$$\EE[X_{\tau}]=\EE[\xi_1] \EE[\tau]=0\cdot \EE[\tau]=0 \text{ so that }
0 = \EE[X_{\tau}]=p_0 (-x)+p_a (a-x).$$ 

We now have a system of two linear equations with two unknowns, and solving it yields
$$p_0= \frac{a-x}{a}, \ p_a=\frac{x}{a}.$$ 
It is remarkable that the two probabilities are proportional to the amounts of
money the gambler needs to make (lose) in the two outcomes. The
situation is different when $p\not=\tot$.
</div>

In order to be able to use Wald's identity, we need to check its conditions. We have already seen that 
$\tau$ needs to be a stopping time, and not just any old random time. There are also two conditions about the expected values of $\tau$ and of $\xi_1$. If you read the above solution carefully, you will realize that we never checked whether $\EE[\tau]<\infty$. We should have, but we did not because we still don't have the mathematical tools to do it. We will see later that, indeed, $\EE[\tau]<\infty$ for this particular stopping time. In general, the condition that $\EE[\tau]<\infty$ is important, as the following simple example shows:

<div class="problem">
  Let $\seqz{X}$ be a simple symmetric random walk, and let $\tau_1$ be the first hitting time of the level $1$.
  Use Wald's identity to show that $\EE[\tau]=+\infty$.
</div>
<div class="solution">
  Suppose, to the contrary, that $\EE[\tau]<\infty$. Since $\EE[\delta_1]<\infty$ and $\tau_1$ is a stopping time, Wald's identity applies:
  $$ \EE[X_{\tau_1}] = \EE[ \delta_1] \cdot \EE[\tau_1].$$
  The right hand side is then equal to $0$ because $\EE[\delta_1]=0$. On the other hand, $X_{\tau_1}=1$: the value of $X_n$ when it first hits the level $1$ is, of course, $1$. This leads to a contradiction $1=\EE[X_{\tau_1}] = \EE[\delta_1] \EE[\tau_1] = 0$. Therefore, our initial assumption that $\EE[\tau_1]<\infty$ was wrong!
</div>

## Additional problems for Chapter 4

<!--
  3-max-problems
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01_Random_Walks/3-max-problems_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01_Random_Walks/3-max-problems_sol.Rmd"}
```
</div>


<!--
  time_until_hit
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01_Random_Walks/time_until_hit_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01_Random_Walks/time_until_hit_sol.Rmd"}
```
</div>



<!-- 
  Luke_cookies
  -------------------------------
-->
<div class="problem">
```{r child="problems/01_Random_Walks/Luke_cookies_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01_Random_Walks/Luke_cookies_sol.Rmd"}
```
</div>
 

<!--
  catalan
  ------------------------------------------------
-->
<div class="problemec">
```{r child="problems/01_Random_Walks/catalan_prb.Rmd"}
```
</div>
<!-- <div class="solution"> -->
<!-- ```{r child="problems/01_Random_Walks/catalan_sol.Rmd"} -->
<!-- ``` -->
<!-- </div> -->

<!--
  no_return_to_zero
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01_Random_Walks/no_return_to_zero_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01_Random_Walks/no_return_to_zero_sol.Rmd"}
```
</div>


<!--
  hit_times_1
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01b_Advanced_Random_Walks/hit_times_1_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01b_Advanced_Random_Walks/hit_times_1_sol.Rmd"}
```
</div>

<!--
  min_stopping_times
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01b_Advanced_Random_Walks/min_stopping_times_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01b_Advanced_Random_Walks/min_stopping_times_sol.Rmd"}
```
</div>

<!--
  stopping_times_2
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01b_Advanced_Random_Walks/stopping_times_2_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01b_Advanced_Random_Walks/stopping_times_2_sol.Rmd"}
```
</div>

<!--
  stopping_times_3
  ------------------------------------------------
-->
<div class="problem">
```{r child="problems/01b_Advanced_Random_Walks/stopping_times_3_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/01b_Advanced_Random_Walks/stopping_times_3_sol.Rmd"}
```
</div>



⬇︎ In case you were wondering, the text below belongs to footnotes from somewhere high above.⬇︎


