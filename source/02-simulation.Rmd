```{r child="mydefs.Rmd"}
```

# Simulation of Random Variables and Monte Carlo
<div style="counter-reset: thechapter 2;"> </div>


In the spirit of "learn by doing", these lecture notes contain many "Problems".
The green ones come with solutions and usually introduce new concepts and feature a *Comments* section right after the solution. These comments are subdivided into *R* and
*Math* comments focusing on the computational or conceptual features,
respectively. Note that you are not expected to be able to do the green
problems before reading their solutions and comments, so don't worry if you
cannot. It is a good practice to try, though. Problems in the Additional Problems section,  which are left unsolved,
however, do not require any new ideas and are there to help you practice the
skills presented before.

## Simulation of some common probability distributions

... where we also review some probability along the way.

<div class="example">
''Draw'' 50 simulations from the geometric distribution with parameter $p=0.4$.
</div>

<p class="solution">
```{r}
rgeom(50,prob=0.4)
```
</p>

<div class="comments">

*R:* R makes it very easy to simulate draws from a large class of *named
distributions*^[There are infinitely many ways random variables can be
distributed. Indeed, in the discrete ${\mathbb N}$-valued case only, any
sequence of nonnegative numbers $(p_n)_n$ such that $\sum_n p_n=1$ defines
*a* probability distribution. It turns out, however, that a small-ish number of
distributions appear in nature much more often then the rest. These
distributions, like the normal, uniform, exponential, binomial, etc. turn out to
be so important that they each get a name (hence *named distributions*). ],
such as geometric, binomial, uniform, normal, etc. For a list of all available
distributions, run `help("distributions")` Each available distribution has an *R
name*; the uniform is `unif` the normal is `norm` and the binomial is `binom`,
etc. If you want to simulate $n$ draws (aka a *sample* of size $n$) from a
distribution, you form a full command by appending the letter `r` to its R name
and use $n$ as an argument. That is how we arrived to `rgeom(50)` in the
solution above. The additional arguments of the function `rgeom` have to do with
the parameters of that distribution. Which parameters go with which
distributions, and how to input them as arguments to `rgeom` or `rnorm` is best
looked up in R's extensive documentation. Try `help("rnorm")`, for example. 

*Math:* 
You could spend your whole life trying to understand what it really means to
"simulate" or "generate" a random number. The numbers you obtain from so-called
*random number generators* (RNG) are never random. In fact, they are completely
deterministically generated. Still, sequences of numbers obtained from (good)
random number generators share so many properties with sequences of mythical
*truly* random numbers, that we can use them as if they were truly random. For
the purposes of this class, you can assume that the numbers R gives you as
*random* are random enough. Random number generation is a fascinating topic at
the intersection of number theory, probability, statistics, computer science and
even philosophy, but we do not have the time to cover any of it in this class.
If you want to read a story about a particularly bad random number generator, go
[here](https://en.wikipedia.org/wiki/RANDU).



You might have encountered a geometric distribution before. A random variable with that
distribution can take any positive integer value or $0$, i.e., its support is 
${\mathbb N}_0=\{0,1,2,3,\dots\}$. 
As you can see from the output above, the value $0$ appears more often than the value $3$,
and the value $23$ does not appear at all in this particular simulation run. The 
probability of seeing the value $k\in \{0,1,2,3,\dots\}$ as a result of a single 
draw is given by $(1-p)^k p$, where $p$ is called the *parameter* of the distribution. 

That corresponds to the following interpretation of the geometric distribution:
keep tossing a biased coin (with probability p of obtaining H) until you see the first H; the  number Ts before that is that value your geometric random variable^[Some books will define the geometric random variables as the number of *tosses* (and not Ts) before the first H is obtained. In that case, the final H is included into the count. Clearly, this definition and the one we have given differ by $1$, and this is really not a big deal, but you have to be careful about what is meant when a geometric random variable is mentioned.]
If we put these probabilities in a single table (and choose $p=0.4$, for example) it is 
going to look like this:
```{r echo=FALSE}
k=0:7
df = data.frame(dgeom(k, prob=0.4))
names(df)=c("Prob.")
tf=data.frame(t(df))
tf$elip = c("...")
names(tf) = c(0:7,'...')
knitr::kable(tf, digits=3)
```

Of course, the possible values our random variable can take do not stop at $7$.
In fact, there are infinitely many possible values, but we do not have infinite
space. Note that even though the value $23$ does not appear in the output of the
command `rgeom` above, it probably would if we simulated many more than $50$
values. Let's try it with $500$ draws - the table below counts how many $0s$,
$1s$, $2s$, etc. we got:

```{r echo=FALSE}
X = rgeom(500, prob = 0.4)
knitr::kable(t(table(X)))
```

Still no luck, but we do observe values above 5 more often. By trial and error,
we arrive at about $1,000,000$ as the required number of simulations:

```{r echo=FALSE, message=FALSE}
library(tidyverse)
cts = as.vector(table(rgeom(1000000, prob = 0.4)))
out  = as_tibble(t(cts), .name_repair = "unique")
names(out) = as.character(c(-1+1:length(out)))
out = select(out, head(names(out),4), tail(names(out),5) )
out[,5]=c("...")
names(out)[5]="..." 
kable(out)
```
</div>

<div class="example">
Compute the probability that among $1,000,000$ draws of a geometric random
variable with parameter $p=0.4$, we never see a number greater than $22$.
</div>

<p class="solution">
First, we compute the probability that the value seen in a *single* draw does not exceed $22$:
```{r echo=2}
options(digits=7)
pgeom(22,prob=0.4)
```
Different draws are *independent* of each other, so we need to raise this to the power $1,000,000$. 
```{r}
(pgeom(22,prob=0.4))^(1000000)
```
</p>

<div class="comments">
*R.* The command we used here is `pgeom` which is a cousin of `rgeom`. In
general, R commands that involve named probability distributions consist of two
parts. The prefix, i.e., the initial letter (`p` in this case) stands for the
operation you want to perform, and the rest is the R name of the distribution.
There are 4 prefixes, and the commands they produce are

| Prefix   | Description                                    |
|:----------|:------------------------------------------------|
| `r` | Simulate **r**andom draws from the distribution.  |
| `p` | Compute the cumulative **p**robability distribution function (cdf) (**NOT pdf**)|
| `d` | Compute the probability **d**ensity (pdf) or the probability mass function (pmf) 
| `q` | Compute the **q**uantile function |

(see the Math section below for the reminder of what these things are). In this
problem, we are dealing with a geometric random variable $X$, which has a
discrete distribution with support $0,1,2,3,\dots$. Therefore, the R name is
`geom`. We are interested in the probability $\PP[ X\leq 22]$, which
corresponds to the cdf of $X$ at $x=22$, so we use the 
the prefix `p`. Finally, we used the named parameter `p` and gave it the value `p = 0.4`, because the geometric distribution has a single parameter $p$.

This problem also gives us a chance to discuss precision. As you can see, the
probability of a single draw not exceeding $22$ is very close to $1$. In fact,
it is equal to it to 5 decimal places. By default, R displays 7 significant
digits of a number. That is enough for most applications (and barely enough for
this one), but sometimes we need more. For example, let's try to compute the
probability of seeing no T (tails) in 10 tosses of a biased coin, where the
probability of H (heads) is 0.9.
```{r almost-one}
1-0.1^10
```
While very close to it, this probability is clearly not equal to $1$, as suggested by the output above. 
The culprit is the default precision. We can increase the precision (up to $22$ digits) using the  `options` command
```{r echo = 1:2}
options(digits=17)
1-0.1^10
options(digits=7)
```
Precision issues like this one should not appear in this course, but they will
out there "in the wild", so it might be a good idea to be aware of them.

*Math.* If you forgot all about pdfs, cdfs and such things here is a little reminder:

|   |   |
|---|--------------------|
| cdf | $F(x) = \PP[X\leq x]$|
| pdf | $f(x)$ such that $\PP[X \in [a,b]] = \int_a^b f(x) \, dx$ for all $a<b$ |
| pmf | $p(x)$ such that $\PP[X=a_n] = p(a_n)$ for some sequence $a_n$ |
| qf | $q(p)$ is a number such that $\PP[ X \leq q(p)] = p$


Those random variables that admit a pdf are called **continuous**. The prime
examples are the normal, or the exponential distribution. The ones where a pmf
exists are called **discrete**. The sequence $a_n$ covers all values that such
a, discrete, random variable can take. Most often, $a_n$ either covers the set
of all natural numbers $0,1,2,\dots$ or a finite subset such as $1,2,3,4,5,6$. 

Coming back to our original problem, we note that the probability we obtained is
quite small. Since $1/0.000372$ is about $2690$, we would have to run about
$2690$ rounds of $1,000,000$ simulations before the largest number falls below
$23$.
</div>


<div class="example"> 
Compute the $0.05$, $0.1$, $0.4$, $0.6$ and $0.95$ quantiles of the normal 
distribution with mean $1$ and standard deviation $2$.
</div>

<p class="solution">
```{r}
qnorm( c(0.05, 0.1, 0.4, 0.6, 0.95), mean = 1, sd = 2)
```
</p>

<div class="comments">
*R.* The function we used is `qnorm`, with the prefix `q` which computes the
quantile function and the R name `norm` because we are looking for the quantiles
of the normal distribution. The additional (named) parameters are where the
parameters of the distribution come in (the mean and the standard variation) in
this case. Note how we plugged in the entire vector
`c(0.05, 0.1, 0.4, 0.6, 0.98)` instead of a single value into `qnorm`. You can
do that because this function is **vectorized**. That means that if you give it
a vector as an argument, it will "apply itself" to each component of the vector
separately, and return the vector of results. Many (but not all) functions in R
are vectorized^[The function `sum` adds up all the components of the vector.
You would not want such a function to be vectorized. If it were, it would return
exactly the same vector it got as input.].

As a sanity check, let's apply `pnrom` (which computes the cdf of the normal) to these quantile values:
```{r}
p =  qnorm( c(0.05, 0.1, 0.4, 0.6, 0.95), mean = 1, sd = 2)
pnorm( p , mean = 1, sd = 2)
```
As expected, we got the original values back - the normal quantile function and its cdf are inverses of each other. 

*Math.* Computing the cdf of a standard normal is the same thing reading a
*normal table*. Computing a quantile is the opposite; you go into the middle of
the table and find your value, and then figure out which "Z" would give you that
value. 
</div>


<div class="example">
Simulate $60$ throws of a fair $10$-sided die. 
</div>

<p class="solution">
```{r}
sample( 1:10 , 60, replace = TRUE)
```
</p>

<div class="comments">
*Math.* Let $X$ denote the outcome of a single throw of a fair $10$-sided die.
The distribution of $X$ is discrete (it can only take the values
$1,2,\dots, 10$) but it is not one of the more famous named distributions. I
guess you could call it a *discrete uniform on ${1,2,\dots, 10}$*, but a better
way to describe such distribution is by a **distribution table**, which is
really just a list of possible values a random variable can take, together with
their, respective, probabilities. In this case, 

```{r echo=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
options(knitr.table.format = "html") 
library(tidyverse)
x = 1:10
y = rep("0.1", 10)
knitr::kable(t(y), col.names = 1:10, escape = FALSE)

```
*R.* The command used to draw a sample from a (finite) collection is, of, course
`sample`. The first argument is a vector, and it plays the role of the "bag"
from which you are drawing. If we are interested in repeated, random samples, we
also need to specify `replace = FALSE` otherwise, you could draw any single
number at most once:
```{r}
sample(1:10, 8, replace = FALSE)
```
 With more than 10 draws, we would run out of numbers to draw:
```{r error=TRUE}
sample(1:10, 12, replace = FALSE)
```
The bag you draw from can contain objects other than numbers:
```{r echo=2}
set.seed(400)
sample( c("Picard", "Data", "Geordi"), 9, replace = TRUE)
```
So far, each object in the bag had the same probability of being drawn. You can
use the `sample` command to produce a *weighted* sample, too. For example, if we
wanted to simulate $10$ draws from the following distribution
```{r echo=FALSE}
knitr::kable(t(c(0.2,0.7, 0.1)), col.names = c(1,2,3)) %>% 
   kable_styling(full_width = F)
```
we would use the additional argument `prob`:
```{r echo=2}
set.seed(513)
sample( c(1,2,3), 10, replace = TRUE, prob = c(0.2,0.7, 0.1))
```
Note how it is mostly $2$s, as expected.
</div>

<div class="example">
Draw a sample of size $n=10$ from $N(1,2)$, i.e., from the normal distribution
with parameters $\mu=1$, $\sigma = 2$. Plot a histogram of the obtained
values. Repeat for $n=100$ and $n=100000$. 
</div>


<p class="solution">

```{r}
x = rnorm(10, mean = 1, sd = 2)
hist(x)
```
```{r}
x = rnorm(100, mean = 1, sd = 2)
hist(x)
```
```{r}
x = rnorm(100000, mean = 1, sd = 2)
hist(x)
```
</p>

<div class="comments">

*R.* It cannot be simpler! You use the command `hist`, feed it a vector of
values, and it produces a histogram. It will even label the axes for you. If you
want to learn how to tweak various features of your histogram, type `?hist`.

<!-- Esthetically, the built-in histograms leave something to be desired. We can do better, using the package `ggplot2`. You don't have to use it in this class, but if you want to, you install it first by running `install.packages("ggplot2")` (you have to do this only once). Then, every time you want to use it, you run `library(ggplot2)` to notify R that you are about to use a function from that package. It would take a whole semester to learn everything there is to know about `ggplot2`; I will only show what a histogram looks like in it: -->
<!-- ```{r} -->
<!-- library(ggplot2) -->
<!-- x = rnorm(100000, mean = 1, sd = 2) -->
<!-- qplot(x, bins=40) -->
<!-- ``` -->
*Math*. Mathematically, histogram can be produced for any (finite) sequence of
numbers: we divide the range into several bins, count how many of the points in
the sequence falls into each bin, and then draw a bar above that bin whose
height is equal (or proportional to) that count. The picture tells use about how
the sequence we started from is "distributed". The order of the points does not
matter - you would get exactly the same picture if you sorted the points first.
If the sequence of points you draw the histogram of comes from, say, normal
distribution, the histogram will resemble the shape of the pdf of a normal
distribution. I say resemble, because its shape is ultimately random. If the
number of points is small (like in the second part of this problem) the
histogram may look nothing like the normal pdf. However, when the number of
points gets larger and larger, the shape of the histogram gets closer and closer
to the underlying pdf (if it exists). I keep writing "shape" because the three
histograms above have very different scales on the $y$ axis. That is because we
used counts to set the vertical sizes of bins.
A more natural choice is to use the proportions, i.e. relative frequencies (i.e.
counts divided by the total number of points) for bar heights. More precisely, the bar height $h$ over the bin $[a,b]$ is chosen so that the area of the bar, i.e., $(b-a)\times h$ equals to the proportion of all points that fall inside $[a,b]$. This way, the total area under the histogram is always $1$. To draw such a **density histogram** in R we would
need to add the additional option `freq = FALSE` to `hist`:
```{r}
x = rnorm(100000, mean = 1, sd = 2)
hist(x,freq = FALSE)
```

Note how the $y$-axes label changed from "Frequency" to "Density". 
With such a normalization, the histogram of $x$ can be directly compared to the
probability density of a normal distribution. Here is a histogram of $100,000$
simulations from our normal distribution with its density function (pdf)
superimposed; I am leaving the code in case you are interested:

```{r echo=2:6}
set.seed(1098)
sims = rnorm(10000, mean = 1, sd = 2)
x = seq(-6,8,by=0.02)
y = dnorm(x, mean = 1, sd = 2)
hist(sims, freq=FALSE, main = "")
points(x,y, type="l", lwd=3, col="red" )
```
</div>

## Multivariate Distributions

<div class="example">
Let `x` contain $2,000$ draws from $N(0,1)$, `z` another $2,000$ draws from $N(0,1)$ and let `y=x^2+z`. 

1. Draw a scatterplot of `x` and `y` to visualize the joint distribution of `x` and `y`

2. Plot two histograms, one of `x` and one of `y`. Do they tell the whole story about the joint distribution of `x` and `y`?
   
3. Are `x` and `y` correlated? Do `x` and `y` in your plot "look independent"?  Use the permutation test to check of independence between `x` and `y`. 
</div>

<p class="solution">

<part> 1. </part>

```{r}
x = rnorm(2000)
z = rnorm(2000)
y = x^2+z
plot(x,y)
```

<part> 2. </part>

```{r echo=2:3}
par(mfrow=c(1,2))
hist(x)
hist(y)
```

No, the two histograms would not be enough to describe the joint distribution.
There are many ways in which two random variables $X$ and $Y$ can be jointly
distributed, but whose separate (marginal) distributions match the histograms
above. To give a very simple example, let $X$ and $Y$ be discrete random
variables, each of which can only take values $0$ or $1$. Consider the following
two possible *joint* distribution tables for the random pair $(X,Y)$:


```{r echo=FALSE}
library(kableExtra)

jd1 = data.frame(c(0.25, 0.25),
                c(0.25, 0.25))
rownames(jd1) = c(" 0"," 1")
colnames(jd1) = c('0','1')

jd2 = data.frame(c(0.5, 0),
                c(0, 0.5))
rownames(jd2) = c(" 0"," 1")
colnames(jd2) = c('0','1')

t1 = kable(jd1) %>% 
   row_spec(0, align="center") %>% 
   column_spec(1, bold = T) %>% 
   kable_styling(full_width = F, "striped")

t2 = kable(jd2) %>% 
   row_spec(0, align="center") %>% 
   column_spec(1, bold = T) %>% 
   kable_styling(full_width = F, "striped") 

knitr::kables(list(t1,t2))

   
```

In both cases, the marginals are the same, i.e., both $X$ and $Y$ are equally
likely to take the value $0$ or $1$, i.e., they both have the Bernoulli
distribution with parameter $p=1/2$. That would correspond to the separate
histograms to be the same. On the other hand, their joint distributions (aka
dependence structures) are completely different. In the first (left) case, $X$
and $Y$ are independent, but in the second they are completely dependent.

<part> 3. </part>

They are probably not correlated since the sample correlation between `x`
and `y` is close to $0$:
```{r}
(cor(x,y))
```
but they do not look independent.


To apply the permutation test, we first plot the scatterplot of `x` vs. `y` as
above. Then, we replace `y` by a vector with the same components, but randomly
permute their positions, and then plot a scatterplot again. We repeat this three
times:
```{r echo=2:12}
par(mfrow=c(2,2))
y_perm_1 = sample(y)
y_perm_2 = sample(y)
y_perm_3 = sample(y)
plot(x,y)
plot(x,y_perm_1)
plot(x,y_perm_2)
plot(x,y_perm_3)
```

The conclusion is clear, the first (upper-left) plot is very different than the
other three. Therefore, `x` and `y` are probably not independent.
</p>

<div class="comments">
*Math.* The point of this problem is to review the notion of the **joint
distribution** between two random variables. The most important point here is
that there is more to the joint distribution of two random vectors, than just
the two distributions taken separately. In a sense, the whole is (much) more
than the sum of its parts. This is something that does not happen in the
deterministic world. If you give me the $x$-coordinate of a point, and,
separately, its $y$-coordinate, I will be able to pinpoint the exact location of
that point. 

On the other hand, suppose that the $x$-coordinate of a point is unknown, so we
treat it as a random variable, and suppose that this variable admits the
standard normal distribution. Do the same for $y$. Even with this information,
you cannot say anything about the position of the point $(x,y)$. It could be
that the reason we are uncertain about $x$ and the reason we are uncertain about
$y$ have nothing to do with each other; in that case we would be right to assume
that $x$ and $y$ are independent. If, on the other hand, we got the values of
both $x$ and $y$ by measuring them using the same, inaccurate, tape measure, we
cannot assume that the errors are independent. It is more likely that both $x$
and $y$ are too big, or both $x$ and $y$ are too small.

Mathematically, we say that random variables $X$ and $Y$ are independent if 
$$\PP[X \in [a,b]] \times \PP[ Y \in [c,d] ] = \PP[ X\in [a,b] \text{ and } Y\in [c,d]]\text{ for all } a,b,c,d.$$ 
While up to the point,
this definition is not very eye-opening, or directly applicable in most cases.
Intuitively, $X$ and $Y$ are independent if the distribution of $Y$ would not
change if we received additional information about $X$. In our problem, random
variables $X$ and $Y$ correspond to vectors `x` and `y`. Their scatterplot above
clearly conveys the following message: when `x` is around $-2$, we expect `y` to
be around `4`, while when `x` is around $0$, `y` would be expected to be around
$0$, too.

Sometimes, it is not so easy to decide whether two variables are independent by staring at a scatterplot. What would you say about the scatterplot below?
```{r echo=FALSE, fig.asp=1, out.width="50%"}
x1 = sin(runif(3000,0,2*pi)**2)
y1 = cos(runif(3000,0,2*pi)**2)
plot(y1~x1, xlab="x", ylab="y",asp=1, xlim=c(-1,1))
```
The **permutation test** is designed to help you decide when two (simulated)
random variables are likely to be independent. The idea is simple. Suppose that
`x` and `y` are simulations from two independent (not necessarily identical)
distributions; say `x=runif(1000)` and `y=rnorm(1000)`. The vector
`y_perm=sample(y)` is a randomly permuted version of `y` (see R section below)
and it contains exactly the same information about the distribution of `y` as
`y` itself does. Both `y` and `y_perm` will produce exactly the same histogram.
Permuting `y`, however, "uncouples" it from `x`. If there was any dependence
between the values of `x` and `y` before, there certainly isn't any now. In
other the joint distribution of `x` and `y_perm` has the same marginals as the
joint distribution of `x` and `y`, but all the (possible) dependence has been
removed. What remains is to compare the scatterplot between `x` and `y` and the
scatterplot between `x` and `y_perm`. If they look about the same, we conclude
that `x` and `y` are independent. Otherwise, there is some dependence between
them. 

One question remains: why did we have to draw three scatterplots of permuted
versions of `y`? That is because we have only finitely many data points, and it
can happen, by pure chance, that the permutation we applied to `y` does not
completely scramble its dependence on `x`. With a "sample" of three such plots,
we 
get a better feeling for the inherent randomness in this permutation procedure,
and it is much easier to tell whether "one of these things is not like the
others". Btw, the random variables in the scatterplot above are, indeed,
independent; here are the $4$ permutation-test plots to "prove" it:
```{r, fig.asp=1, echo=FALSE}
x1 = sin(runif(3000,0,2*pi)**2)
y1 = cos(runif(3000,0,2*pi)**2)
par(mfrow=c(2,2))
plot(y1~x1, xlab="x", ylab="y",asp=1, xlim=c(-1,1))
plot(sample(y1)~x1, xlab="x", ylab="y_perm_1",asp=1, xlim=c(-1,1))
plot(sample(y1)~x1, xlab="x", ylab="y_perm_2",asp=1, xlim=c(-1,1))
plot(sample(y1)~x1, xlab="x", ylab="y_perm_3",asp=1, xlim=c(-1,1))

```

Unlike univariate (one-variable) distributions which are visualized using
histograms or similar plots, multivariate (several-variable) distributions are
harder to depict. The most direct relative of the histogram is a **3d
histogram**. Just like the $x$-axis is divided into bins in the univariate case,
in the multivariate case we divide the $xy$-plane into regions (squares, e.g.)
and count the number of points falling into each of these regions. After that
a 3d bar (a skyscraper) is drawn above each square with the height of each
skyscraper equal (or proportional) to the number of points which fall into its
base. Here is a 3d histogram of our original pair (`x`,`y`) from the problem.
You should be able to rotate and zoom it right here in the notes, provided your
browser has JavaScript enabled:

<div align="center">
```{r, echo=FALSE, fig.align="center"}
htmltools::includeHTML("pics/3dhist.html")
```
</div>

A visualization solution that requires less technology would start the same way,
i.e., by dividing the $xy$ plane into regions, but instead of the third
dimension, it would use different colors to represent the counts. Here is an
example where the regions are hexagons, as opposed to squares; it just looks
better, for some reason:

```{r echo=FALSE}
library(hexbin)
df=data.frame(x,y)
hexbinplot(y~x, data=df, colramp = heat.ob, asp=1)
```

Just to showcase the range of possibilities, here is another visualization
technique which which requires deeper statistical tools, namely the 
**density contour plot**:
```{r echo=FALSE, out.width="80%"}
library(ggplot2)
ggplot(data=df, aes(x=x, y=y) ) +
  geom_density_2d(color="black", bins=12)+
   theme_classic()+
   theme(aspect.ratio=0.8)
```

*R.* There is very little new R here. You should remember that if `x` and `y` are
vectors of the same length, `plot(x,y)` gives you a scatterplot of `x` and `y`.

To compute the sample correlation between two vectors, use the `cor`. 

We used the command `sample(y)` to obtain a randomly permuted version of `y`.
The simplicity of this is due to default parameters of the command `sample`
which we already learned about. In particular, the default number of samples is
exactly the size of the input vector `y` and, by default, sampling is performed
*without replacement*. If you think about it for a second, you will realize that
a sample of size $n$ from the vector of size $n$ *without* replacement is
nothing by a random permutation of `y`. 

You are not required to do this in your submissions, but if you want to display
several plots side-by-side, use the command is `par(mfrow=c(m,n))` before the
`plot` commands. It tells R to plot the next $mn$ plots in a $m\times n$ grid.

</div>

<div class="example">
Let the random variables $X$ and $Y$ have the joint distribution given by 
the following table:

```{r echo=FALSE}
library(kableExtra)
df = data.frame(matrix(c(0.1,0.2,0.3,0.2,0.2,0.0),
                       nrow=2, byrow=TRUE))
colnames(df) = c("1","2","3")
rownames(df) = c("1","2")
kable(df, striped=TRUE) %>% 
   kable_styling(full_width=FALSE)
```
   
Simulate $10,000$ draws from the distribution of $(X,Y)$ and display a 
contingency table of your results.
</div>

<p class="solution">

```{r tidy=FALSE}
joint_distribution_long = data.frame(
   x = c(1, 1, 1, 2, 2, 2),
   y = c(1, 2, 3, 1, 2, 3)
)
probabilities_long = 
       c(0.1, 0.2, 0.3, 0.2, 0.2, 0.0)

sampled_rows = sample(
   x = 1:nrow(joint_distribution_long),
   size = 10000,
   replace = TRUE,
   prob = probabilities_long
)

draws = joint_distribution_long[sampled_rows, ]

table(draws)
```

</p>

<div class="comments"> 
*Math.* The main mathematical idea is to think of *each pair* of possible values
of $X$ and $Y$ as a separate "object", put all these objects in a "bag", then
then draw from the bag. In other words, we convert the bivariate distribution
from the problem to the following univariate distribution

```{r echo=FALSE}
library(tidyverse)
paired = joint_distribution_long %>% 
   transmute(val=str_c("(", x,",",y,")"))

knitr::kable(t(probabilities_long), col.names=paired$val, striped=TRUE) %>% 
   kable_styling( full_width=FALSE)
```

and sample from it. When you do, you will get a vector whose elements are pairs
of numbers. The last step is to extract the components of those pairs into
separate vectors. 

*R.* The most important new R concept here is `data.frame`. You should think of
it as a spreadsheet. It is, mathematically, a matrix, but we do not perform any
mathematical operations on it. Moreover, not all columns in the data frame have
to be numeric. Some of them can be strings, and other can be something even more
exotic. You should think of a data frame as a bunch of column vectors of the
same length stacked side by side. It is important to note that each column of a
data frame will have a name, so that we don't have to access it by its position
only (as we would have to in the case of a matrix).  

In this class, the column vectors of data frames are going to contain simulated
values. In statistics, it is data that comes in data frames, with rows
corresponding to different observations, and columns to various observed
variables.

The easiest way to construct a data frame using already existing vectors is as follows:

```{r}
x = c(1,2,3)
y = c("a","b","c")
(df=data.frame(x,y))
```

Note that the two columns inherited their names from the vectors `x` and `y`
that fed into them. Note, also, that all rows got consecutive numerical values
as names by default. Row names are sometimes useful to have, but are in general
a nuisance and should be ignored (especially in this class). Column names are
more important, and there is a special notation (the dollar-sign notation) that
allows you to access a column by its name:

```{r}
df$y
```

If you want to give your columns custom names (or if you are building them out
of explicitly given vectors as in the solution above) use the following syntax

```{r}
z = c("a","b","c","d")
(df = data.frame( letters = z, numbers = c(1,2,3,4)))
```

A feature that data frames share with vectors and matrices is that you can use vector indexing as in the following example (where `df` is as above)

```{r}
df[c(2,4,4,1),]
```

Make sure you understand why the expression inside the brackets is `c(2,4,4,1),`
and not `c(2,4,4,1)`. R's desire to keep row names unique leads to some
cumbersome constructs such as `4.1` above. As I mentioned before, just disregard
them. 

A nice thing about data frames is that they can easily be pretty-printed in
RStudio. Go to the Environment tab in one of your RStudio panes, and double
click on the name of the data frame you just built. It will appear as a nicely
formatted spreadsheet. 

Once we have the data frame containing all $6$ pairs of possible values $X$ and
$Y$ can take (called `joint_distribution_long` in the solution above), we can
proceed by sampling from its rows, by sampling from the set `1,2,3,4,5,6` with
probabilities `0.1, 0.2, 0.3, 0.2, 0.2, 0.0`. The result of the corresponding
`sample` command will be a sequence - called `sampled_rows` in the solution - of
length $10,000$ composed of numbers $1,2,3,4,5$ or $6$. The reason we chose the
name `sampled_rows` is because each number corresponds to a row from the data
frame `joint_distribution_long`, and by indexing `joint_distribution_long` by
`sampled_rows` we are effectively sampling from its rows. In other words, the
command `joint_distribution_long[sampled_rows, ]` turns a bunch of numbers into
a bunch of rows (many of them repeated) of the data frame
`joint_distribution_long`. 

The final step is to use the function `table`. This time, we are applying it to
a data frame and not to a vector, but the effect is the same. It tabulates all
possible combinations of values of the columns, and counts how many times each
of them happened. The same result would have been obtained by calling
`table(draws$x, draws$y)`. 
</div>


## Monte Carlo

<div class="example">
Use Monte Carlo to estimate the expected value of the exponential random
variable with parameter $\ld = 4$ using $n=10$, $n=1,000$ and $n=1,000,000$
simulations. Compare to the exact value.
</div>

<p class="solution">

```{r echo = c(2,4)}
set.seed(12341)
x = rexp(10, rate=4)
err = 0.25 - mean(x)
mean(x)
```

For an exponential random variable with parameter $\ld$, the expected value is 
$1/\ld$ (such information can be found in [Appendix A](./dist.html)) which, 
in this case, is  $0.25$. The error made was `r format(err,digits=5)` for $n=10$ simulations.

We increase the number of simulations to $n=1000$ and get a better result

```{r echo = c(2,4)}
set.seed(12342)
x = rexp(1000, rate=4)
err = 0.25 - mean(x)
mean(x)
```

with (smaller) error `r format(err, digits=5)`. Finally, let's try $n=1,000,000$:

```{r echo = c(2,4)}
set.seed(12342)
x = rexp(1000000, rate=4)
err = 0.25 - mean(x)
mean(x)
```

The error is even smaller `r format(err, digits=5)`. 
</p>
<!-- This can be obtained quite easily by integration (by parts): -->
<!-- $$ \EE[X] = \int_{-\infty}^{\infty} x f(x)\, dx = \int_0^{\infty} x \ld e^{-\ld x}\, dx = \tfrac{1}{\ld}$$ -->

<div class="comments">

*R.* The only new thing here is the command `mean` which computes the mean of a vector. 

*Math.* There is a lot going on here conceptually. This is the first time we
used the Monte Carlo method. It is an incredibly useful tool, as you will keep
being reminded throughout this class. The idea behind it is simple, and it is
based on the *Law of large numbers*:

**Theorem** Let $X_1,X_2, \dots$ be an independent sequence of random
variables with the same distribution, for which the expected value can be
computed. Then
$$ \tfrac{1}{n} \Big( X_1+X_2+\dots+X_n\Big) \to \EE[X_1] \text{ as } n\to\infty$$
The idea behind Monte Carlo is to turn this theorem "upside down". The goal is
to compute $\EE[X\_1]$ and use a supply of random numbers, each of which
comes from the same distribution, to accomplish that. The random number
generator inside `rexp` gives us a supply of numbers (stored in the vector `x`)
and all we have to do is compute their average. This gives us the left-hand side
of the formula above, and, if $n$ is large enough, we hope that  this average
does not differ too much from its theoretical limit. As $n$ gets larger, we
expect better and better results. That is why your error above gets smaller as
$n$ increases. 

It looks like Monte Carlo can only be used to compute the expected value of a
random variable, which does not seem like such a bit deal. But it is! You will see
in the sequel that almost anything can be written as the expected value of
*some* random variable.
</div>

<div class="example">
Use Monte Carlo to estimate $\EE[X^2]$, where $X$ is a standard normal 
random variable. 
</div>

<p class="solution">

You may or may now know that when $X$ is standard normal $Y=X^2$ has a $\chi^2$
distribution with one degree of freedom. If you do, you can solve the problem
like this:

```{r}
y = rchisq(5000 ,df=1)
mean(y)
```

If you don't, you can do the following: 

```{r}
x = rnorm(5000)
y = x^2
mean(y)
```

</p>

<div class="comments">

*Math+R.* We are asked to compute $\EE[ X^2]$, which can be interpreted in
two ways. First, we can think of $Y=X^2$ as a random variable in its own right and you
can try to take draws from the distribution of $Y$. In the case of the normal
distribution, the distribution of $Y$ is known - it happens to be a
$\chi^2$-distribution with a single degree of freedom (don't worry if you never
heard of it). We can simulate it in R by using its R name `chisq` and 
get a number close to the exact value of $1$. 

If you did not know about the $\chi^2$ distribution, you would not know what R
name to put the prefix `r` in front of. What makes the simulation possible is
the fact that $Y$ is a *transformation* of 
a random variable we know how to simulate. In that case, we simply simulate the
required number of draws `x` from the geometric distribution (using `rnorm`) and
then apply the transformation $x \mapsto x^2$ to the result. The transformed
vector `y` is then nothing but the sequence of draws from the distribution of
$X^2$. 

The idea described above is one of main advantages of the Monte Carlo technique:
if you know how to simulate a random variable, you also know how to simulate
any (deterministic) function of it. That fact will come into its own a bit later
when we start working with several random variables and stochastic processes,
but it can be very helpful even in the case of a single random variable, as you
will see in the next problem. 

</div>

<div class="example">
Let $X$ be a standard normal random variable. Use Monte Carlo to estimate the
probability $\PP[ X > 1 ]$. Compare to the exact value.
</div>

<p class="solution">

The estimated probability:

```{r tidy=FALSE}
x = rnorm(10000)
y = x > 1
(p_est = mean(y))
```

The exact probability and the error

```{r}
p_true = 1-pnorm(1)
(err = p_est-p_true)
```

</p>

<div class="comments">

*R.* As we learned before,  the symbol `>` is an operation, which returns a Boolean (`TRUE` or `FALSE`) value. For example:

```{r}
1>2
```
```{r}
5^2>20
```

It is vectorized:

```{r}
x = c(1,2,4)
y = c(5,-4,3)
x>y
```

and recycling rules apply to it (so that you can compare a vector and a scalar, for example)

```{r}
x = 1:10
x>5
```

Therefore, the vector `y` in the solution is a vector of length $10000$ whose
elements are either `TRUE` or `FALSE`; here are the first 5 rows of data frame
with columns `x` and `y` from our solution:

```{r echo=FALSE}
set.seed(2123)
df = data.frame(x = rnorm(100000), y = x > 1)[1:5,]
kable(df, digits = 4) %>% 
   kable_styling(full_width = FALSE)
``` 

Finally, `z` contains the `mean` of `y`. How do you compute a mean of Boolean values?  In R (and many other languages) `TRUE` and `FALSE` have default numerical values, usually $1$ and $0$. This way, when $R$ is asked to compute the `sum` of a Boolean vector it will effectively count the number of values which are `TRUE`. Similarly, the `mean` is the relative proportion of `TRUE` values. 

*Math.* We computed the **proportion** of the "times" $X>1$ (among many simulations of $X$) and used it to approximate the **probability** $\PP[ X>1]$.  More formally, 
we started from a random variable $X$ with a normal distribution and then transformed it into another random variable, $Y$, by setting $Y=1$ whenever $X>1$ and $0$ otherwise. This is often written as follows
$$ Y = \begin{cases} 1, & X>1 \\ 0, & X\leq 1.\end{cases}$$
The random variable $Y$ is very special - it can only take values $0$ and $1$ (i.e., its support is $\{0,1\}$). Such random variables are called **indicator random variables**, and their distribution, called the **Bernoulli distribution**, always looks like this:

```{r echo=FALSE}
library(tidyverse)
library(kableExtra)
knitr::kable(t(c("1-p", "p")), col.names = c(0,1)) %>% 
   kable_styling(full_width = F)
```
for some $p \in [0,1]$. The parameter $p$  is nothing but the probability $\PP[Y=1]$. 

So why did we decide to transform $X$ into $Y$? Because of the following simple fact:
$$ \EE[ Y] = 1 \times p + 0 \times (1-p) = p.$$
The expected value of an indicator is the probability $p$, and we know that we can use Monte Carlo whenever we can express the quantity we are computing as an expected value of a random variable we know how to simulate. 
</div>

Many times, simulating a random variable is easier than analyzing it analytically. Here is a fun example:

<div class="example">
Use Monte Carlo to estimate the value of $\pi$ and compute the error. 
</div>

<p class="solution">

```{r tidy=FALSE}
nsim = 1000000
x =  runif(nsim,-1, 1)
y =  runif(nsim,-1, 1)
z = (x ^ 2 + y ^ 2) < 1
(pi_est = 4 * mean(z))
(err = pi_est - pi)
```
</p>

<div class="comments">

*Math.*
```{r echo=FALSE, out.width= "50%", out.extra='style="float:right; padding:10px"'}
knitr::include_graphics('pics/mc_pi.gif')
```
As we learned in the previous problem, probabilities of events can be computed using Monte Carlo, as long as we know how to simulate the underlying indicator random variable. In this case, we want to compute $\pi$, so we would need to find a "situation" in which the probability of something is $\pi$. Of course, $\pi>1$, so it cannot be a probability of anything, but $\pi/4$ can, and computing $\pi/4$ is as useful as computing $\pi$. To create the required probabilistic "situation" we think of the geometric meaning of $\pi$, and come up with the following scheme. Let $X$ and $Y$ be two independent uniform random variables each with values between $-1$ and $1$. We can think of the pair $(X,Y)$ as a random point in the square $[-1,1]\times [-1,1]$. This point will sometimes fall inside the unit circle, and sometimes it will not. What is the probability of hitting the circle? Well, since $(X,Y)$ is uniformly distributed everywhere inside the square, this probability should be equal to the portion of the area of our square which belongs to the unit circle. The area of the square is $4$ and the area of the circle is $\pi$, so the required probability is $\pi/4$. Using the idea from the previous problem, we define the indicator random variable $Z$ as follows
$$ Z = \begin{cases} 1 & (X,Y) \text{ is inside the unit circle, } \\ 0 & \text{ otherwise.}
\end{cases}
= \begin{cases} 1& X^2+Y^2 < 1, \\ 0 & \text{ otherwise.} \end{cases}$$
</div>

<div class="example">
1. Write an R function `cumavg` which computes the sequence of running averages of a vector, i.e., if the input is $x=(x_1,x_2,x_3,\dots, x_n)$, the output should be
$$ \Big(x_1, \frac{1}{2} (x_1+x_2), \frac{1}{3}(x_1+x_2+x_3), \dots, \frac{1}{n} (x_1+x_2+\dots+x_n)\Big).$$ Test it to check that it really works. (*Hint:* look up the function `cumsum`. )
   
2. Apply `cumavg` to the vector $4 z$ from the previous problem and plot your results (use a smaller value for `nsim`. Maybe $1000$.) Plot the values against their index. Add a red horizontal line at the level $\pi$. Rerun the same code (including the simulation part) several times.
</div>


<p class="solution">

<part> 1. </part>

```{r}
cumavg = function(x) {
   c = cumsum(x)
   n = 1:length(x)
   return(c / n)
}
x = c(1, 3, 5, 3, 3, 9)
cumavg(x)
```

<part> 2. </part>

```{r tidy=FALSE}
nsim = 1000
x =  runif(nsim,-1, 1)
y =  runif(nsim,-1, 1)
z = (x ^ 2 + y ^ 2) < 1
pi_est = cumavg(4 * z)
plot(
   1:nsim,
   pi_est,
   type = "l",
   xlab = "number of simulations",
   ylab = "estimate of pi",
   main = "Computing pi by Monte Carlo"
)
abline(pi, 0,
       col = "red")
```
</p>

<div class="comments">

Part 1. Once you know about `cumsum`, the problem becomes much easier. 

Part 2. This course is not about R graphics, but I think it is a good idea to teach you how to make basic plots in R. We already used the function `plot` to draw scatterplots.
By default, each point drawn by `plot` is marked by a small circle so it might not seem like a good idea to use it. Luckily this, and many other things, can be adjusted by numerous additional arguments. One of such arguments is `type` which determines the type of the plot. We used `type="l"` which tells R to join the points with straight lines:
```{r}
x = c(1,3,4,7)
y = c(2,1,5,5)
plot(x,y, type="l")
```
The other arguments, `xlab`, `ylab` and `main` determine labels for axes and the entire plot. The function `abline(a,b)` adds a line $y = a x + b$ to an already existing plot. It is very useful in statistics if one wants to show the regression line superimposed on the scatterplot of data. Finally, the argument `col`, of course, determines the color of the line. To learn about various graphical parameters, type `?par`. 

*Math.* The conceptual reason for this exercise is to explore (numerically) the kinds of errors we make when we use Monte Carlo. Unlike the deterministic numerical procedures,  Monte Carlo has a strange property that no bound on the error can be made with absolute certainty. Let me give you an example. Suppose that you have a biased coin, with the probability $0.6$ of heads and $0.4$ of tails. You don't know this probability, and use a Monte Carlo technique to estimate it - you toss your coin $1000$ times and record the number of times you observe $H$. The law of large numbers suggests that the relative frequency of heads is close to the true probability of $H$. Indeed, you run a simulation
```{r echo=2:10}
set.seed(1234)
x = sample( c("T","H"), 1000, prob = c(0.4, 0.6), replace = TRUE)
y = x == "H"
mean(y)
```
and get a pretty accurate estimate of $0.594$. If you run the same code a few more times, you will get different estimates, but all of them will be close to $0.6$. Theoretically, however, your simulation could have yielded $1000$ Hs, which would lead you to report $p=1$ as the Monte-Carlo estimate. The point is that even though such disasters are theoretically possible, they are exceedingly unlikely. The probability of getting all $H$ in $1000$ tosses of this coin is a number with more than $500$ zeros after the decimal point.  

The take-home message is that even though there are no guarantees, Monte Carlo performs well the vast majority of the time. The crucial ingredient, however, is the number of simulations. The plot you were asked to make illustrates exactly that. The function `cumavg` gives you a whole sequence of Monte-Carlo estimates of the same thing (the number $\pi$) with different numbers of simulations `nsim`. For small values of `nsim` the error is typically very large (and very random). As the number of simulations grows, the situations stabilizes and the error decreases. Without going into the theory behind it, let me only mention is that in the majority of practical applications we have the following relationship:
$$ error \sim \frac{1}{\sqrt{n}}.$$
In words, if you want to double the precision, you need to quadruple the number of simulations. If you want an extra digit in your estimate, you need to multiply the number of simulations by $100$. Here is an image where I superimposed $40$ plots like the one you were asked to produce (the red lines are $\pm \frac{4}{\sqrt{n}}$):

```{r echo=F, warning = F}
library(tidyverse)
library(latex2exp)
nsim = 250
ns = 1:nsim
single = function() {
   x =  runif(nsim, -1, 1)
   y =  runif(nsim, -1, 1)
   z = (x ^ 2 + y ^ 2) < 1
   return(4*cumsum(z)/ns)
}
nbatch = 40
S = data.frame(t(replicate(nbatch,single() ))) %>% 
   mutate(omega = factor(1:nbatch)) %>% 
   pivot_longer(starts_with("X"), 
                names_prefix = "X",
                values_to = "estimate") %>% 
   mutate(time = as.numeric(name)) %>% 
   group_by(omega)
E = data.frame( time = 1:nsim, error = 4/sqrt(1:nsim))

ggplot(S, aes(x=time, y=estimate-pi, group = omega)) +
   geom_line(size=0.3, color="#999999")+
   geom_path(aes(time, error), data = E, inherit.aes = F, color="red") +
   geom_path(aes(time, -error), data = E, inherit.aes = F, color="red") +
   theme_bw()+
   xlab("number of simulations")+
   ylab("error")+
   ggtitle(TeX("Errors in  Monte Carlo estimation of $\\pi$"))
```
</div>

## Conditional distributions

<div class="example">
Let $X$ and $Y$ be two independent geometric random variables with parameters $p=0.5,$ and let $Z=X+Y$. Compute $\PP[ X = 3| Z = 5]$ using simulation. Compare to the exact value. 
</div>

 
<p class="solution">

By simulation:

```{r tidy=FALSE, echo=2:10}
set.seed(1211)
nsim = 1000000
X = rgeom(nsim, prob = 0.5)
Y = rgeom(nsim, prob = 0.5)
Z = X + Y
X_cond = X[Z == 5]
mean(X_cond  == 3) 
```

To get the exact value, we start from the definition:
$$ \PP[ X = 3 | Z= 5 ] = \frac{\PP[ X=3 \eand Z=5]}{\PP[Z=5]} = \frac{\PP[X=3 \eand Y = 2]}{\PP[Z=5]}, $$
where the last equality follows from the fact that $\{ X=3 \text{ and } Z=5 \}$ is exactly the same event as $\{ X = 3 \text{ and } Y=2\}$. 
Since $X$ and $Y$ are independent, we have 
$$\PP[ X=3 \eand Y=2 ] = \PP[X=3] \times \PP[ Y=2] = 2^{-4} 2^{-3} = 2^{-7}.$$
To compute $\PP[ Z = 5]$ we need to split the event $\{ Z = 5 \}$ into events we know how to deal with. Since $Z$ is built from $X$ and $Y$, we write
$$ \begin{align} \PP[ Z = 5 ] = &\PP[X=0 \eand Y=5]+ \PP[ X=1 \eand Y=4] + \PP[ X=2 \eand Y=3] + \\
&  \PP[ X=3 \eand Y=2] + \PP[ X=4 \eand Y=1] + \PP[ X = 5 \eand Y=0]. \end{align}$$
Each of the individual probabilities in the sum above is $2^{-7}$, so $\PP[ X = 3 | Z = 5] = \frac{1}{6}$. 
This gives us an error of `r mean(X_cond == 3) - 1/6`.
</p>

<div class="comments">

*Math.*  Let us, first, recall what the conditional probability is. The definition we learn in the probability class is the following $$ \PP[A | B] = \frac{\PP[A \eand B]}{\PP[B]},$$ as long as $\PP[B]>0$. The interpretation is that $\PP[A|B]$ is still the probability of $A$, but now in the world where $B$ is guaranteed to happen. Conditioning usually happens when we receive new information. If someone tells us that $B$ happened, we can disregard everything in the complement of $B$ and adjust our probability to account for that fact. First we remove from $A$ anything that belongs to the complement of $B$, and recompute the probability $\PP[A \cap B]$. We also have to divide by $\PP[B]$ because we want the total probability to be equal to $1$. 

Our code starts as usual, but simulating $X$ and $Y$ from the required distribution, and constructing a new vector $Z$ as their sum.  The variable `X_cond` is new; we build it from $X$ by removing all the elements whose corresponding $Z$ is *not* equal to $5$. This is an example of what is sometimes called the **rejection method** in simulation. We simply "reject" all simulations which do not satisfy the condition we are conditioning on. We can think of `X_cond` as bunch of simulations of $X$, but in the world where $Z=5$ is guaranteed to happen. Once we have `X_cond`, we proceed as usual by computing the relative frequency of the value $3$ among all possible values $X$ can take. Note that the same `X_cond` can also be used to compute the conditional probability $\PP[ X=1| Z=5]$. In fact, `X_cond` contains the information about the entire **conditional distribution of $X$ given $Z=5$**; if we draw a histogram of `X_cond`, we will get a good idea of what this distribution looks like:
```{r echo=F}
hist(X_cond, breaks=seq(-0.5,5.5, by=1))
```
Since `X_cond` contains only discrete values from $0$ to $5$, a contingency table might be a better tool for understanding its distribution:
```{r echo=FALSE}
library(kableExtra)
kable(t(table(X_cond))) %>% 
  kable_styling(full_width=FALSE)
```

The histogram and the table  above suggest that  the distribution of $X$, given $Z=5$, is uniform on $\{0,1,2,3,4,5\}$. It is - a calculation almost identical to the one we performed above gives that $\PP[ X= i| Z=5] = \frac{1}{6}$ for each $i=0,1,2,3,4,5$. 

One more observation at the end. Note that we drew $n=1,000,000$ simulations this time. While it is probably an overkill for this particular example, conditional probabilities in general require more simulations than unconditional ones. Of course, that is because we reject most of our original draws. Indeed, the size of the vector `X_cond` is `r length(X_cond)` - more than a $20$-fold decrease. This fact becomes particularly apparent when we try to use Monte Carlo for  conditional distributions associated with *continuous* random vectors as we will see in out next problem. 
</div>

<div class="example">
Let $X$ and $Y$ be independent random variables where $X$ has the $N(0,1)$ distribution and $Y$ the exponential distribution with parameter $\ld=1$. Find a graphical approximation to the conditional density of $Y$, given $X+Y\geq 1$. Repeat the same, but condition on $X+Y=1$.  
</div>

<p class="solution">

```{r}
nsim=100000
x=rnorm(nsim)
y=rexp(nsim)

cond = x+y >= 1
x_cond=x[cond]
hist(x_cond, breaks=100)

```

```{r}
nsim=100000
eps=0.1
x=rnorm(nsim)
y=rexp(nsim)
cond = (1-eps < x+y) & (x+y<1+eps)
x_cond=x[cond]
hist(x_cond, breaks=100)

```

</p>

<div class="comments">
*Math.* In the case of conditioning on $X+Y\geq 1$ we repeated the same procedure as in the discrete case. We simply rejected all draws that do not satisfy the condition.

When Conditioning on $X+Y=1$, however, you immediately encounter a  problem  that you don't get with discrete distributions. The event $\{ X+Y=1\}$ has probability $0$ and will never happen.
That means that our strategy form the previous problem will simply not work - you will reject **all** draws. The problem goes beyond a particular approach to the problem, as the conditional probabilities such as $\PP[ Y \geq 0 | X+Y=1]$ are not well defined. Indeed, the formula
$$ \PP[ Y \geq 0 | X+Y=1] "=" \frac{\PP[ Y\geq 0 \text{ and } X+Y=1]}{ \PP[X+Y=1]}$$
requires that the probability in the denominator be strictly positive. Otherwise you are dividing by zero. The theoretical solution to this is by no means simple and requires mathematics beyond the scope of these notes. Practically, there is a very simple way of going around it. Instead of conditioning on the zero-probability event $X+Y=1$, we use  a slightly more relaxed condition
$$ X+Y \in (1-\eps, 1+\eps) $$ for a small, but positive, $\eps$. In many cases of interest, this approximation works very well, as long as $\eps$ is not too big. How big? Well, that will depend on the particular problem, as well as on the number of simulations you are drawing. The best way is to try several values and experiment. For example, if we chose $\eps=0.01$ in our problem, the number of elements in `x_cond` (i.e., the number of non-rejected draws) would be on the order of $100$, which may be considered to small to produce an accurate histogram. On the other hand, when $\eps=1$, your result will be inaccurate because. The rule of thumb is to take the smallest $\eps$ you can, while keeping the number of non-rejected draws sufficiently large. 
</div>


## Additional Problems for Chapter 2

<div class="problem">

```{r child = 'problems/00_R/Sim-Weibull_prb.Rmd'}
```
</div>
<div class="solution">

```{r child = 'problems/00_R/Sim-Weibull_sol.Rmd'}
```

</div>

<div class="problem">

```{r child="problems/00_R/Sim-trans_prb.Rmd"}
```

</div>

<div class="solution">

```{r child="problems/00_R/Sim-trans_sol.Rmd"}
```

</div>

<div class="problem">
```{r child="problems/00_R/Sim-FX_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-FX_sol.Rmd"}
```
</div>

<div class="problemec">
```{r child="problems/00_R/Sim-mix_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-mix_sol.Rmd"}
```
</div>

<div class="problem">
```{r child="problems/00_R/Sim-perm_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-perm_sol.Rmd"}
```
</div>

<div class="problem">
```{r child="problems/00_R/Sim-disc_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-disc_sol.Rmd"}
```
</div>

<div class="problem">
```{r child="problems/00_R/Sim-int_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-int_sol.Rmd"}
```
</div>

<div class="problem">
```{r child="problems/00_R/Sim-tricyl_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-tricyl_sol.Rmd"}
```
</div>

<div class="problemec">
```{r child="problems/00_R/Sim-monty_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-monty_sol.Rmd"}
```
</div>


<div class="problem">
```{r child="problems/00_R/Sim-joint-cond_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-joint-cond_sol.Rmd"}
```
</div>

<div class="problem">
```{r child="problems/00_R/Sim-disease_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-disease_sol.Rmd"}
```
</div>


<div class="problem">
```{r child="problems/00_R/Sim-cube_prb.Rmd"}
```
</div>
<div class="solution">
```{r child="problems/00_R/Sim-cube_sol.Rmd"}
```
</div>


 In case you were wondering, the text below belongs to footnotes from somewhere high above.